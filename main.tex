\input{template.tex}
\usepackage{fancyvrb, framed, verbatim}
\usepackage{listings}
\usepackage[T1]{fontenc}
\definecolor{shadecolor}{rgb}{.9, .9, .9}  %These were defined for when I used to use the verbatim environment, they are not used now normally.
\newenvironment{code} %
   {\snugshade\verbatim}%
   {\endverbatim\endsnugshade}



\lstset{ 
  language=C,
  backgroundcolor=\color[rgb]{0.1,0.1,0.1},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  showstringspaces=false,          % So that it hides the spaces in strings
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  firstnumber=1,                % start line enumeration with line 1
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{gray}, % the style that is used for the line-numbers
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  tabsize=2,	                   % sets default tabsize to 2 spaces
  commentstyle=\color{YellowGreen},    % comment style
  stringstyle=\color{DarkOrchid},     % string literal style
 % keywordstyle=\color{ForestGreen},       % keyword style
  upquote=true         fn           %Fixing the quotes
}

\pagecolor[rgb]{0.1,0.1,0.1} %page colour is frosted screen black
\color[rgb]{0,0.6,0} %text colour is phosphor green



\title{Rust Course notes}
\author{Razafy Rindra, ``Hagamena''}

\begin{document}

\maketitle
\tableofcontents
\newpage
\section{Introduction}
Some quick notes from the Rust book, and the ``Let's Get Rusty'' \href{https://youtube.com/playlist?list=PLai5B987bZ9CoVR-QEIN9foz4QCJ0H2Y8}{online course}
\section{Common Programming Concepts in Rust}
\subsection{Variables and Mutability}
\subsubsection{Mutable variables} 
Variables in Rust are immutable by default. In order to createe a mutable variable, we need to add in `mut' in front of the name like so:
\begin{lstlisting}
    fn main() {
        let mut x = 5;
        println!("The value of x is: {x}");
        x = 6;
        println!("The value of x is: {x}"); 
}
\end{lstlisting}


\subsubsection{Constants} We can also declare constants in Rust like so:
\begin{lstlisting}
    const my_number: u32 = 100_000;
\end{lstlisting}

Constants unlike variables can't be mutable, need to be type annotated and they can't be assigned to return value of a function or any value computed at run time.

\subsubsection{Shadowing}
Shadowing allows us to create a new variable with an existing name, for example:
\begin{lstlisting}
    let x = 5;
    println!("The value of x is: {x}");
    let x = "six";
    println!("The value of x is: {x}");
\end{lstlisting}

\subsection{Data Types}
\begin{definition}
    \textbf{Scalar data types} represent a single value, \textbf{Compound data types} represent a goup of values
\end{definition}
Types of scalar data types\begin{enumerate}
    \item Integers, they can be 8,16,32,64,128 bit signed or unsigned integers.
    \item Floating-point numbers
    \item Booleans
    \item Character, they represent unicode character
\end{enumerate}
Type of compound data types\begin{enumerate}
    \item Tuples; a fixed size array of data that can be of different values.
    \begin{lstlisting}
        let tup = ("Let's Get Rusty!",100_000);
    \end{lstlisting}
    \item Arrays, in Rust they are fixed length.
\end{enumerate}
\subsection{Functions}
Functions are defined with an fn keyword like so:\begin{lstlisting}
    fn my_function(x: i32,y: i32){
         println!("The value of x is: {}", x);
         println!("The value of y is: {}", y);
    }
\end{lstlisting}

A piece in code in Rust are either a statement or an expression. Statements perform some action but do not return any value, whilst expressions returns values. 
\begin{lstlisting}
    fn my_function(x: i32,y: i32) -> i32{
         println!("The value of x is: {}", x);
         println!("The value of y is: {}", y);
         x+y
    }
\end{lstlisting}

In this function, the println are statements since they don't return anything while `x+y' is an expression, it is returned by the function (note the last expression of a function is implicitely returned). 

\subsection{Control Flow}
\subsubsection{if statements}
As in other programming languages:\begin{lstlisting}
 fn main() {
    let number = 3;

    if number < 5 {
        println!("first condition was true");
    } else if number < 22{
        println!("second condition was true.")
    }else{
        println!("condition was false");
    }
}
\end{lstlisting}
Note, the condition must be a boolean. We can also set a ``if-else'' statement in a let statemetn.\begin{lstlisting}
    fn main() {
    let condition = true;
    let number = if condition { 5 } else { 6 };

    println!("The value of number is: {number}");
}
\end{lstlisting}
\subsubsection{Loops}
We can create loops with the `loop' keyword, which will execute the code in it until we call break.\begin{lstlisting}
    let mut counter = 0;
    let result = loop{
       counter += 1;
       if counter == 10{
            break counter;
       }
    };
\end{lstlisting}

We can also use the while statement:\begin{lstlisting}
    let mut number = 3;
    while number != 0{
        println!("{}!", number);
        number -= 1;
    }
\end{lstlisting}

Finally the third type of loop we can create are `for loops'\begin{lstlisting}
    let a = [10,20,30,40,50];
    
    for element in a.iter{
        println!("The value is: {}", element);
    }
\end{lstlisting}

We can also loop over a range:\begin{lstlisting}
    for number in 1..4{
        println!("{}!", number);
    }
\end{lstlisting}
The last number of the range is excluded.
\section{Ownership}
\paragraph*{What is ownership?}
The ownership model is a way to manage memory. How do we manage memory today?\begin{enumerate}
    \item Garbage collection.
Used in high level languages like java or $C\#$, the Garbage collection manages memory for you.
It's pros is that is error free, you don't have to manage memory yourself so you won't introduce memory bugs. It also faster write time.

It's cons is that you have no control over memory, it is slower and has unpredictable runtime performance and larger program size since you got to include a garbage collector.

    \item Manual memory management
    
It's pros are that you have higher control over memory, faster runtime and smaller program size. But it is error prone and has slower writing time.

Notice that these two have opposite trade-offs.

    \item Ownership model
    
This is the way Rust manages memory, it's pros are control over memory, faster runtime and smaller program size and is error free (though it does allow for you to opt-out of memory safetey).
It's cons is that you have a slower write time, slower than with Manual memory management, Rust has a strict set of rules around memory management.
\end{enumerate}

\paragraph*{Stack and Heap}
During runetime program has access of stack and heap, stack is fixed size and cannot grow or shrink during runetime and it creates stack-frames for each function 
it executes. Each stack frames stores the local variables of the function they execute, their size are calculated during compile time and variables in stack frames 
only live as long as the stack lives.

\

The heap grows and shrinks during runtime and the data stored can be dynamic in size and we control the lifetime of the data.

Pushing to the stack is faster than allocating on the heap since the heap has to spend time looking for a place to store the data, also accessing data on the stack is faster 
than accessing data on the heap, since on the heap we must follow the pointer.

\begin{lstlisting}
    let x = "hello";
\end{lstlisting}
This is a string litteral and has fixed size and is stored in the stack-frame.

\begin{lstlisting}
    let x = String::from(world");
\end{lstlisting}
x is of type String which can be dynamic in size so it can't be stored on the stack, we ask the heap to allocate memory for it 
and it passes back a pointer, which is what is stored on the stack. 

\subsection{Ownership Rules}

\begin{enumerate}
    \item Each value in Rust has a variable called its owner.
    \item There can only be one owner at a time.
    \item When the owner goes out of scope, the value will be dropped.
\end{enumerate}

\begin{example}

    \

    \begin{lstlisting}
        fn main(){
            let x = 5;
            let y = x; // Copy

            let s1 = String::from("hello");
            let s2 = s1; // move (not a shallow copy)

            println!("{}, world", s1);
        }
    \end{lstlisting}
This returns an error since when we created s2 we made it point to the same ``hello'' on the heap that s1 points to, but in order to 
ensure memory safetey, Rust invalidates s1. 

What if we do want to clone the string? Use the clone() method: \begin{lstlisting}
    fn main(){
        let x = 5;
        let y = x; // Copy

        let s1 = String::from("hello");
        let s2 = s1.clone();

        println!("{}, world", s1);
    }
\end{lstlisting}
\end{example}

\subsection{Ownership and functions}
\begin{example}

    \

    \begin{lstlisting}
        fn main(){
            let s = String::from("hello);
            takes_ownership(s);
            println!("{}", s);
        }

        fn takes_ownership(some_string: String){
            println!("{}", some_string);
        }
    \end{lstlisting}

This gives us an error since after we pass a parameter in a function it is the same as if we assign the parameter to another variable.

So we move s into some\_string and after takes\_ownership scope is done some\_string is dropped.

\begin{example}
    
    \

    \begin{lstlisting}
        fn main() {
            let s1 = gives_ownership();
            println!("s1 = {}", s1);
        }

        fn gives_ownership(){
            let some_string = String::from("hello");
            some_string // returning the string moves ownership to s1
        }
    \end{lstlisting}
\end{example}
\begin{example}
    
    \

    \begin{lstlisting}
        fn main() {
        let s1 = gives_ownership();         // gives_ownership moves its return
                                            // value into s1
    
        let s2 = String::from("hello");     // s2 comes into scope
    
        let s3 = takes_and_gives_back(s2);  // s2 is moved into
                                            // takes_and_gives_back, which also
                                            // moves its return value into s3
    } // Here, s3 goes out of scope and is dropped. s2 was moved, so nothing
      // happens. s1 goes out of scope and is dropped.
    
    fn gives_ownership() -> String {             // gives_ownership will move its
                                                 // return value into the function
                                                 // that calls it
    
        let some_string = String::from("yours"); // some_string comes into scope
    
        some_string                              // some_string is returned and
                                                 // moves out to the calling
                                                 // function
    }
    
    // This function takes a String and returns one
    fn takes_and_gives_back(a_string: String) -> String { // a_string comes into
                                                          // scope
    
        a_string  // a_string is returned and moves out to the calling function
    }
    \end{lstlisting}
    

\end{example}

Moving ownership and giving back is tedious, what if we just want to use variable without taking ownership? Use references.

\end{example}
\subsection{References}

Let us see how references fix the following situation\begin{lstlisting}
    fn main() {
    let s1 = String::from("hello");

    let (s2, len) = calculate_length(s1);

    println!("The length of '{}' is {}.", s2, len);
}

fn calculate_length(s: String) -> (String, usize) {
    let length = s.len(); // len() returns the length of a String

    (s, length)
}
\end{lstlisting}

Here in order to calculate the length of the string without taking ownershipe, we need to return a tuple that returns both the string and the length.

\begin{lstlisting}
    fn main() {
        let s1 = String::from("hello");
    
        let len = calculate_length(&s1);
    
        println!("The length of '{}' is {}.", s1, len);
    }
    
    fn calculate_length(s: &String) -> usize {
        let length = s.len(); // len() returns the length of a String
        length 
    }
\end{lstlisting}

Here s is a reference of a string and takes no ownership of the string, it points to s1 which points to the string.
So when the function finishes executing s is dropped without affecting s1.

\begin{definition}
    Passing in references as function paramaters is called \textbf{borrowing}. Since we are not taking ownership of the parameters.
\end{definition} 
Note that references are immutable by default, so how to we modify value without taking ownership?

Mutable references:

\begin{lstlisting}
    fn main() {
    let mut s1 = String::from("hello");

    change(&mut s1);
}

fn change(some_string: &mut String) {
    some_string.push_str(", world");
}
\end{lstlisting}

Now change can mutate the value of s1 without taking ownership. Mutable reference have a restriction, we can only have one mutable reference to a particular piece of data 
in a particular scope.

\newpage

\begin{lstlisting}
    fn main() {
    let mut s = String::from("hello");

    let r1 = &mut s;
    let r2 = &mut s; // Returns an error since can not borrow twice.

    println!("{}, {}", r1, r2);
}
\end{lstlisting}

This prevents ``data races'' where two pointers point at the same data and one pointer reads the data and another one tries to write to the data.


What if we try to mix mutable and immutable references? We get another error, we can't have mutable reference if an immutable referece already exists. Immutable reference don't expect the underlying data to change.
But we can have many immutable references, since we don't expect the underlying value to change.

Note the scope of a reference starts when it introduced and ends when it's used for the last time, so we can define a mutable reference when all the immutable references are out of scope(so after we use them for the last time).

\paragraph*{Rules of Refences}\begin{enumerate}
    \item At any given time, we can either have one mutable reference or any number of immutable reference.
    \item References must always be valid.
\end{enumerate}

\subsection{Slices}

\begin{definition}
    Slices let you a contiguous sequence of elements in a collection instead of the whole collection, without taking ownership.
\end{definition}

\begin{lstlisting}
    fn first_word(s: &String) -> usize {
    let bytes = s.as_bytes();

    for (i, &item) in bytes.iter().enumerate() {
        if item == b' ' {
            return i;
        }
    }

    s.len()
}

fn main() {}
\end{lstlisting}

There are two problems with this, the return value of first\_word is not tied to the string.
If we change the string, the value of the length of the first word doesn't change.

If we wanted to return the second word, we must retrurn a tuple with the index at the start of the word and the index at the end of the word.
We have more values we must keep in sync.

Let us use the string slice:

\begin{lstlisting}
    fn main() {
    let mut s = String::from("hello world");

    let hello = &s[..5]; //String Slices, tells us we want the value of the string from index 0 to 4
    let world = &s[6..]; //String Slices, tells us we want the value of the string from index 6 to 10
    
    let s2 = "hello word"; // String litteral are string slices!

    let word = first_word(s2);

    fn first_word(s: &str) -> &str {
        let bytes = s.as_bytes();
    
        for (i, &item) in bytes.iter().enumerate() {
            if item == b' ' {
                return &s[0..i];
            }
        }
    
        &s[..]
    }
    
}

\end{lstlisting}

We can also create slice of array 

\begin{lstlisting}
    fn main(){
        let a = [1,2,3,4,5];
        let slice = &a[0..2]; // This is of type &[i32]
    }
\end{lstlisting}

\newpage

\section{Structs}
\subsection{Defining and Using Structs}
\begin{lstlisting}
//Defining a struct
    struct User{ 
    username: String,
    email: String,
    sign_in_count: u64,
    active: bool,
}

fn main() {
    //Creating an instance of struct
    let mut user1 = User {
        email: String::from("user@email.com"),
        username: String::from("user123"),
        active: true,
        sign_in_count: 1
    };
    let name = user1.username; // Get values from struct with the . operator
    user1.username = String::from("user234"); // modify specific values with . operator
  
    // Creating a new instance of struct with function
    let user2 = build_user(
        String::from("user345@email.com"),
        String::from("user345")
    );

    //We can also create new instances of a struct using existing instances.

    let user3 = User{
        email: String::from("user456@email.com"),
        username:String::from("user456"),
        ..user2 // Takes the remaining field from user2
    };

    // We can also create structs without naming fields, these are called tuple structs

    struct Colour(i32,i32,i32);
    struct Point(i32,i32,i32);

    // Colour and Point have the same fields, but have different type, 
    //so we can't pass a Colour to a function that expects a Point.

}

fn build_user(email: String, username: String) -> User {
    User{
        email, // Since functions arguments have same name as field names, can write it like this...
        username, //...This is called the field init shorthand syntax
        active: true,
        sign_in_count : 1,
    }
}
\end{lstlisting}
\newpage
\subsection{Methods and associated functions}
\begin{lstlisting}
#[derive(Debug)] // Needed to print out, we will look more into this later.
struct Rectangle{
    width: u32,
    height: u32
}

// Creating implementation block for Rectangle struct,
// This will house function and methodes associated with struct

impl Rectangle{
    fn area(&self) -> u32{ // First arguement in method is always self, the instance the method is being called on
            self.width*self.height
    }

    fn can_hold(&self, other: &Rectangle) ->bool{
        self.width > other.width && self.height>other.height
    }
}

//Struct allow us to have multiple impl blocs

// We can also def associated function, unlike methods they aren't tied to an instance of our struct.

impl Rectangle{
    fn square(size: u32) -> Rectangle{
        Rectangle { 
            width: size, 
            height: size 
        }
    }
\end{lstlisting}

\section{Enums and Pattern matching}
Structs and enums are the building blocks for creating new types in Rust. In Rust, enums are most similar to the ones from functional programming.

\subsection{Defining Enums}
Enums allow us to enumerate a list of variants. When is it appropriate to use enums over structs?

\begin{example}
    In this example we use enums to enumerate IP adresses, an IP adresse can be one of only two types, version 4 and version 6. So it is natural to use enums 
if we want to express IP adresses in code.
\newpage
    \begin{lstlisting}
enum IpAddrKind {
    V4(u8, u8, u8, u8), // We can male this code more precise by adding data in the variant
    V6(String),   // Enum variants can store different types of data
}

enum Message{
    Quit,
    Move {x: i32, y: i32},
    Write(String),
    ChangeColor(i32,i32,i32),
}

//Just like strucs we can define methods and associated functions on enum type.

impl Message{
    fn some_fn(){
        println!("Ya-hoo");
    }
}


struct  IpAddr{
    kind: IpAddrKind,
    address: String,
}

fn main() {
    let four = IpAddrKind::V4;
    let six = IpAddrKind::V6;

    let localhost = IpAddrKind::V4(127,0,0,1);
}

//Since V4 and V6 are both variants of IpAddrKind, we can define a function that takes in
//our enum type, and it can take in either V4 or V6

fn route(ip_kind: IpAddrKind) {}
    \end{lstlisting}
\end{example}
\subsection{Option Enum}
Many languages have null values, a value can either exists or it is null (there is no value). But the type system cannot guarentee that if you use 
a value it is not null.

This is not a problem in Rust, since Rust has no null values. We use the option enum.

\begin{lstlisting}
fn main(){
    /*  If we have a value that can possibly be null, we wrap it in the options enum.
    enum Option<T>{
        Some(T), //Some store any value
        None, // None store no value
    }
    This forces the type system to enforce that we handle the None case and guarentees that a value exists in the Some case.*/
       
    let some_number = Some(5);
    let some_string = Some("a string");

    let absent_number: Option<i32> = None; // We need to annotate the type since no value is passed in so Rust can't infer the type.


    let x: i8 = 5;
    let y: Option<i8> = Some(5);

    // let sum = x+y; This code gives an error, since we can't add i8 to an Option<i8>
        

    // In general we need to treat cases if Option is Some or None.

    let sum =x+y.unwrap_or(0); // If y is Some it adds, if y is None it treats it as if it was 0.
}
\end{lstlisting}

\subsection{Pattern Matching}

Recall, match allows us to compare a value to a set of values. This is very useful for enums.

\begin{lstlisting}
    //Using Match Expressions

fn main(){
    value_in_cents(Coin::Quarter(UsState::Alaska));
}

#[derive(Debug)]
enum UsState{
    Alabama,
    Alaska,
    Arizona,
    Arkansas,
    California,
    // ...
}

enum Coin{
    Penny,
    Nickel,
    Dime,
    Quarter(UsState),
}

fn value_in_cents(coin:Coin) -> u8{
    match coin{
        Coin::Penny => {
            println!("Lucky penny!");
            1
        }
        Coin::Nickel => 5,
        Coin::Dime => 10,
        Coin::Quarter(state) => {
            println!("State quarter from {:?}!", state);
            25
        }
    }
}
\end{lstlisting}
This program will output:\begin{verbatim}
    State quarter from Alaska!
\end{verbatim}

\begin{lstlisting}
    //Using Match Expressions with Option<T> enum

fn main(){
    let five = Some(5);
    let six = plus_one(5);
    let none = plus_one(None);
}

fn plus_one(x: Option<i32>) -> Option<i32>{
    match x{
        Some(i) => Some(i+1),
        None => None 
    }
}
/*
Note Match expressions are exhaustive so we need to match all possible values. So if we 
have a lot of types of values, we use the underscore placeholder.
    match x{
        Some(i) => Some(i+1),
        _=> None // underscore means if it is any other pattern execute this code.
    }
*/
\end{lstlisting}
\subsection{Using if let syntax}
\newpage
\begin{lstlisting}
    //Using if let syntax

fn main(){
    let some_value = Some(3);
// Instead of using the match like this, when we only have on case we care about.    
    match some_value{
        Some(3) => println!("three"),
        _=> (),
    }

// We can use the if-let synyax

    if let Some(3) = some_value{ // Says if some_value matches with Some(3) execute the bellow code
        println!("three");
    }
}
\end{lstlisting}

\section{Module}
In previous courses we have just been writting our code in one file, but now we are going to learn to be more organised, we will learn rust's Module system.
\subsection{Packages and Crates}
\begin{definition}
    \textbf{Crates}:

    When we type ``Cargo new'', Rust creates a new package containing crates, which contain modules.

    Crates come in two flavours:\begin{itemize}
        \item Binary crate: Code you can execute
        \item Library crate: Code that can be used by other programs.
    \end{itemize}
\end{definition}

Convention:
If we have ``main.rs'' file in the src directory then a binary crate with the same name as package will be automatically created and main.rs will be the crate root.

\begin{definition}
    \textbf{Crate root}

    Is the source file that rust compiler starts at when building our crate.
\end{definition}

If we have ``lib.rs'' file in the src directory then a library crate with the same name as package will be automatically created and lib.rs will be the crate root.

\paragraph*{Rules around crates}
\begin{itemize}
    \item A package must have at least one crate
    \item A package can have either 0 or 1 library crate
    \item A package can have any number binary crate.
\end{itemize}

If want to make more binary crates, make a folder called bin, each file in that folder will represent another binary crate.


\subsection{Defining Modules}
\newpage
\subsubsection{Definintions, Paths and Privacy}
\begin{lstlisting}
    //Our goal is to create library that helps run a restaurant.

    //We seperate the restaurant in two parts, the front of the house is where the customers are
    //Back of the house is where food is being made, dishes are clean and where manager is.

    mod front_of_house { // module are specified with mod keyword
    // In side this module we have two other modules, modules can contain other modules, structs, enums, constants, traits, etc...
    
    pub mod hosting { //By default a child module and anything inside of it is private from the point of view of parent module.  
    // So need to put the "pub" keyword, so that front_of_house can see hosting and it's contents.
        pub fn add_to_waitlist() {}

            fn seat_at_table() {}
        }

        mod serving {
            fn take_order() {}

            fn serve_order() {}

            fn take_payment() {}
        }
    }


    // If you want to reference an item in module tree (like a funciton), need to specifyt a path to function
    pub fn eat_at_restaurant(){
        // Absolute path
        crate::front_of_house::hosting::add_to_waitlist();

        //Relative path, start from the current module
        front_of_house::hosting::add_to_waitlist();

    }

    fn serve_order(){}

    mod back_of_house{
        fn fix_incorrect_order(){
            cook_order();
            super::serve_order(); // super:: allows us to reference the parent module, in this case crate.
        }

        fn cook_order() {}
    }
\end{lstlisting}
\newpage 

\subsection{Privacy rules when it comes to structs}

\begin{lstlisting}
    //Privacy rules when it comes to structs

    mod back_of_house {
        pub struct Breakfast { // Need to pub keyword to access it.
        pub toast: String, // Even though struct is pub, by default fields are private 
        seasonal_fruit: String,
        }

        impl Breakfast {
            pub fn summer(toast: &str) -> Breakfast {
                Breakfast {
                    toast: String::from(toast),
                    seasonal_fruit: String::from("peaches"),
                }
            }
        }
    }

    pub fn eat_at_restaurant() {
        let mut meal = 
            back_of_house::Breakfast::summer("Rye");
        
        meal.toast = String::from("Wheat");
        
        // Note we need to use summer function to make Breakfast struct.
        // We can't create one directly, since it contains a private field, seasonal_fruit.

        /*
        This gives us an error 
        
        let meal2 = back_of_house::Breakfast{
            toast: String::from("Wheat"),
            seasonal_fruit: String::from("peaches")
        };
        */
    }
\end{lstlisting}

\newpage
\subsubsection{Privacy rules when it comes to enums}

\begin{lstlisting}
    mod back_of_house {
    pub enum Appetizer { 
        Soup, // By default if an enum is public so are it's variants.
        Salad,
    }
}

pub fn eat_at_restaurant() {
    let order1 = back_of_house::Appetizer::Soup;
    let order2 = back_of_house::Appetizer::Salad;
}
\end{lstlisting}

\newpage
\subsubsection{Use keyword}
\paragraph*{Bringing paths into scope with the use keyword.}

\begin{lstlisting}
    mod front_of_house {
    pub mod hosting {
        pub fn add_to_waitlist() {}
    }
}

// In order to not have to specify the whole path to add_to_waitlist each time we call it, we can use the "use" keyword to bring a path in to scope.

// use self::front_of_house::hosting; relative path with "self" referenceing the current module 

pub use crate::front_of_house::hosting; // If we want code that is external to this file to reference hosting::, we need to mark this "pub"


pub fn eat_at_restaurant() {
    let secret_number = rand::thread_rng().gen_range(1, 101);
    hosting::add_to_waitlist();
    hosting::add_to_waitlist();
    hosting::add_to_waitlist();
}




/*  Could have brought the funtion into scope to not have to use hosting::
 But in Rust the idiomatic way to bring a function into scope is to bring it's parent module into scope
 In order to make it clear that add_to_waitlist() function is not a local function.

 If we are bringing enums, struct, other items into scope then we specify the whole path. Except if we are bringing two items with the same name into scope.

For example here:


use std::fmt;
use std::io;

fn function1() -> fmt::Result {
    // --snip--
    Ok(())
}

fn function2() -> io::Result<()> {
    // --snip--
    Ok(())
}

Another way of doing this is to rename our function:

use std::fmt::Result;
use std::io::Result as IoResult;

fn function1() -> Result {
    // --snip--
    Ok(())
}

fn function2() -> IoResult<()> {
    // --snip--
    Ok(())
}
*/
\end{lstlisting}
\newpage 
\paragraph*{Using external packages}
\begin{lstlisting}
    //Use keyword

    /*Instead of this:
    use rand::Rng;
    use rand::CryptoRng;
    use rand::ErrorKind::Transient;
    We can do this:
    */
    
    use rand::{Rng, CryptoRng, ErrorKind::Transient}; // Nested paths
    
     
    /*
    Instead of this:
    use std::io
    use std::io::Write
    
    We can do this:
    
    */
    
    use std::io::{self, Write};
    
    
    //Glob operator:
    // use std::io::* this means all public items underneath io are in scope.     
\end{lstlisting}

\newpage
\subsubsection{Modules in sperate files}
In order to make our code cleaner we can move our module definitions in different files:
\begin{lstlisting}
// In src/lib.rs
mod front_of_house; // This tells Rust, define our module here but get the contents from a different file with the same name as our module.


pub use crate::front_of_house::hosting;

pub fn eat_at_restaurant() {
    hosting::add_to_waitlist();
    hosting::add_to_waitlist();
    hosting::add_to_waitlist();
}
\end{lstlisting}

\begin{lstlisting}
//In src/front_of_house.rs

    pub mod hosting;
\end{lstlisting}

\begin{lstlisting}
// In src/front_of_house/hosting.rs

    pub fn add_to_waitlist() {} // Needs to live in a directory with the same name as parent module.        
\end{lstlisting}

\section{Common Collections}
\begin{definition}
    \textbf{Collection}
These are some useful data structures included in the standard library.

\

Unlike arrays and tuples, collections are allocated on the heap so their size can grow or shrink as needed.
\end{definition}

In this section we will talk about vectors, strings and hashmaps.
\newpage
\subsection{Vectors}
\begin{lstlisting}
    fn main() {
//Vectors
    let a = [1,2,3];
    let mut v:Vec<i32> = Vec::new(); //Vectors can hold any values, so we need to specify the type.
    v.push(1); // Vectors can grow in size, we can add eleements to it with .push()
    v.push(2);
    v.push(3);

    {
        let v2 = vec![1,2,3]; // Can create a vector with initial values like this.
    }// When our scope ends, v2 and all elements in it are dropped.

//Acessing elemetents in vectors

    let mut v = vec![1,2,3,4,5];

    let third = &v[2];
    //  v.push(6);  Error since v is borred as immutable on previous line. If we have an immutable reference to something we expect the underlying value to not change. But if we take a mutable reference to the same thing, the underlying value could change.
    // When we push an element to a vector, we may need to allocated more memory for the new element, so we would move all elements in vector to new location, and our element at the previous line will be pointing to something else.
    println!("The third element is {}", third);

    // If we try to run with third = &v[20], we will get a runtime error, unlike with arrays, we don't get a compile time error. Since at compile time we don't know the size of vector. 

    //If we want to access data gracefully, so that the program doesn't crash at runtime if an invalid index is used.

    match v.get(20) {
        Some(third) => println!("The third element is {}", third),
        None => println!("There is no third element."),
    }

//Iterating over vector.

    for i in &mut v{ // for loop
        *i += 50; // Derefencing operator
        println!("{}", i);
    }

// Storing enum variables

    enum SpreadsheetCell {
        Int(i32),
        Float(f64),
        Text(String),
    }

    let row = vec![
        SpreadsheetCell::Int(3),
        SpreadsheetCell::Text(String::from("blue")),
        SpreadsheetCell::Float(10.12),
    ];

    match &row[1] {
        SpreadsheetCell::Int(i) => println!("{}", i),
        _=> println!("Not an integer!")
    };
}
\end{lstlisting}

\subsection{String}

In higher programming languages, the complexity of strings is abstracted away from the programmer. In lower programming languages, like in Rust, we have to deal with 
that complexity.

\begin{definition}
    \textbf{Strings} are stored as a collection of UTF-8 encoded bytes. 
\end{definition}

What is UTF-8 encoding? We first need to understand ASCII, it is an string encoding. It defines how to take $10's$ and turn them into strings and vice-versa.

Each ASCII character is stored as a byte, and only 7-bits of that byte is used to represent a character. So only 128 unique characters.
It only represents the english alphabet, some special characters and commands.

\

So other countries came up with their own standards to encode characters. So how does a program know what standard to use when interpratating a collection of bytes.

So unicode was created was used to solve this problem. Unicode represent characters from a lot of languages, and other characters like emojis. It is also backwards compatible with ASCII.

\begin{definition}
    \textbf{UTF-8} is a ``variable-width'' character encoding. Each character in UFT-8 can be represented by 1 byte, 2 bytes, 2 bytes or 4 bytes. 
\end{definition}

\paragraph*{Three relevant ways a string is represented in unicode.}


\begin{itemize}
    \item bytes
    \item Scalar values, can think about these as building blocks of characters (this is what the char type refers to). They can be characters or parts of characters.
    \item Grapheme clusters, what we usually mean when we say characters, the glyphs that build up a word. 
\end{itemize}

The problem with indexing into a string Rust doesn't know what value we want to recieve. Bytes, scalaing values or grapheme clusters.

Look at the /collection-strings folder to see the code.

\subsection{Hash maps}

\begin{definition}
    \textbf{Hash maps} allow us to store key-value pairs and uses a hashing function to determine how to place the keys and values.
\end{definition}
\newpage
\begin{lstlisting}
    use std::collections::HashMap;

fn main() {
    let blue = String::from("Blue");
    let yellow = String::from("Yellow");

    let mut scores = HashMap::new();

    scores.insert(blue, 10); //Note we are not passing the strings as references, so we transfer ownership into the hashmap
    scores.insert(yellow,50);

    let team_name = String::from("Blue");
    let score = scores.get(&team_name); //Get method takes a reference to a key and gives us an option, since we can't guarentee a value will be returned, if we pass an invalide key it will return None.

    for (key, value) in &scores{
        println!("{}: {}", key, value);
    }

    println!("-------");

// Updating our Hashmap

    scores.insert(String::from("Blue"), 20); // Overwrites the Blue key with the value 20.

    //If we don't run to overwrite the existing values:

    scores.entry(String::from("Green")).or_insert(30); //If there isn't entry for key insert key with value 30 unless do nothing.
    scores.entry(String::from("Green")).or_insert(40); //Nothing happens here.

    for (key, value) in &scores{
        println!("{}: {}", key, value);
    }
    
    println!("---");

// Updating values based on old value

    let text = "hello world wonderful world";
    // value is how many times the key appears in the string.
    let mut map = HashMap::new();


    //["hello", "world", "wonderful", "word"]
    for word in text.split_whitespace() { //Splits up the string by the whitespace
        let count = map.entry(word).or_insert(0); // .entry retirns an enum representing the value at that key. If the word doesn't exists it adds it to the hashmap and initialises the value to 0. If it does exists it doesn't do anything.
        *count += 1; //or_insert returns a mutable reference to our value, so we can deincrement it and add 1, even if it doesn't do anything sine the key already exists.
    }

    println!("{:?}", map);

}
\end{lstlisting}

\section{Error handling}

\subsection{Panic!}
If program fails in an unrecoverable way we can use panic! macro that quits the program and returns an error message.

\begin{lstlisting}
    fn main() {
    panic!("crash and burn");
}
\end{lstlisting}

This will return \begin{lstlisting}
    thread 'main' panicked at 'crash and burn', src/main.rs:3:5
    note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
\end{lstlisting}

Note if we have a function that sends out a panic! if given some bad inputs, but we have multiple functions that can call this function. If our program panics!, we don't know 
from where the error is comming from. To resolve this problem we use backtrace. 
Like so:

\paragraph*{Code with error}
\begin{lstlisting}
    fn main() {
    a();
}

fn a(){
    b();
}

fn b(){
    c(22);
}

fn c(num: i32){
    if num == 22{
        panic!("Do not pass in 22!");
    }
}
\end{lstlisting}

\paragraph*{Running it with backtrace to see where we have the bad function call}
\begin{lstlisting}
    RUST_BACKTRACE=1 cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
     Running `target/debug/errors`
thread 'main' panicked at 'Do not pass in 22!', src/main.rs:15:9
stack backtrace:
   0: rust_begin_unwind
             at /rustc/a8314ef7d0ec7b75c336af2c9857bfaf43002bfc/library/std/src/panicking.rs:584:5
   1: core::panicking::panic_fmt
             at /rustc/a8314ef7d0ec7b75c336af2c9857bfaf43002bfc/library/core/src/panicking.rs:142:14
   2: errors::c
             at ./src/main.rs:15:9
   3: errors::b // c is being called by b
             at ./src/main.rs:10:5
   4: errors::a // b is being called by a 
             at ./src/main.rs:6:5
   5: errors::main
             at ./src/main.rs:2:5
   6: core::ops::function::FnOnce::call_once
             at /rustc/a8314ef7d0ec7b75c336af2c9857bfaf43002bfc/library/core/src/ops/function.rs:248:5
note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.
\end{lstlisting}

\subsection{Result Enum}
Let's talk with recoverable errors, that we can handle gracefully without crashing. 

We have the ``Result'' Enum, like the options Enum it contains two variable, but in this case they represent success and failure:\begin{lstlisting}
    enum Result<T,E>{
        Ok(T), // represents success
        Err(E), // represents failure
    }
\end{lstlisting}
\newpage
\paragraph*{An example, using the result enum to deal with errors opening files}
\begin{lstlisting}
    use std::fs::File;
    use std::io::ErrorKind; //Let us match on the type of error we get

fn main(){
    let f = File::open("hello.txt"); //Returns an Result Enum

    let f = match f{  //Need to resolve what we do with the different enum variables
        Ok(file) =>file, // Assign the file to f
        Err(error) => match error.kind(){ // If there is an error match based on the kind of error
                ErrorKind::NotFound => match File::create("hello.txt"){ // If file doesn't exists create the file
                    Ok(fc) => fc, // If no error we can create the file
                    Err(e) => panic!("Problem creating the file: {:?}", e) // If there is error panic!
                },
                other_error=>{ // If we get an error not of the file not found kind panic!
                    panic!("Problem opening the file: {:?}", other_error)
                }
        }
    };

// Another way to write this code using closures. More about this in chapter 13

    let f = File::open("hello.txt").unwrap_or_else(|error| { // This will give us back the file or call this anonymous function, aka closure |error|{...}
        if error.kind() == ErrorKind::NotFound {
            File::create("hello.txt").unwrap_or_else(|error| {
                panic!("Problem creating the file: {:?}", error);
            })
        } else {
            panic!("Problem opening the file: {:?}", error);
        }
    });
}
\end{lstlisting}

\paragraph*{Useful functions on the Result enum}
\begin{lstlisting}
    use std::fs::File;

fn main(){
//  let f = File::open("new_hello.txt").unwrap(); 

    let f = File::open("new_hello.txt").expect("Failed to open new_hello.txt"); 


//we can use unwrap() to do the same this as the below match expression. 
//we can use the expect() method, if we also want to specify the error message that is passed when we panic!

    /*
        let f = match f{
            Ok(file) => file,
            Err(error) => panic!("Problem opening file: {:?}", error),
        };
    */
}
\end{lstlisting}

\subsection{Error propagation}

\begin{definition}
    When we have a function whose implementation calls something that can fail, we often want to return that error back to the caller instead of handling it in the function.

    This is called \textbf{error propagation}        
\end{definition}
\newpage
\paragraph*{A first attempt at dealing with errors with error propagation}
\begin{lstlisting}   
#![allow(unused)]

use std::fs::File;
use std::io::{self, Read};
fn read_username_from_file() -> Result<String, io::Error> {
    let f = File::open("hello.txt");

     let mut f = match f {
         Ok(file) => file, //If opening the file succeds we take that file and store it in f
         Err(e) => return Err(e), // If opening the file fails we take the error and return it
     };

    let mut s = String::new(); 

     match f.read_to_string(&mut s) { // Read the contents of the file and store it in the string
         Ok(_) => Ok(s), 
         Err(e) => Err(e),
     } //read_to_string returns a result type, if we have success we return the string in error we return error.

    }
    fn main() {}
\end{lstlisting}

\paragraph*{A cleaner way to use error propagation, with the ? operator}
\begin{lstlisting}
    
#![allow(unused)]
use std::fs::File;
use std::io::{self, Read};

fn read_username_from_file() -> Result<String, io::Error> {
    let mut f = File::open("hello.txt")?; //The ? operator says, if we succed in opening the file the file is returned and stored in f, if we fail it reurns error
    let mut s = String::new(); 

    f.read_to_string(&mut s)?; // If this call fails, the function will return error
    Ok(s) //If we get to this line, read_to_string succeeded so we return the string
}
fn main() {}
\end{lstlisting}
This code gives us the same output as in the previous screen.


\paragraph*{Reducing our codes to three lines}
\begin{lstlisting}   

#![allow(unused)]
use std::fs::File;
use std::io::{self, Read};

fn read_username_from_file() -> Result<String, io::Error> {
    let mut s = String::new();
    File::open("hello.txt")?.read_to_string(&mut s)?;
    Ok(s) 
}
fn main() {}
\end{lstlisting}

Can our code get simpler? Yes, we can reduce it to one line by bringing fs into scope
\paragraph*{Ultimate implematation}
\begin{lstlisting}

#![allow(unused)]
use std::fs::{self, File};
use std::io::{self, Read};

fn read_username_from_file() -> Result<String, io::Error> {
    fs::read_to_string("hello.txt")
}

fn main() {}
\end{lstlisting}

What happens if we try to use our ? operator in the main function? Since our main function doesn't return anything we get an error:

\begin{lstlisting}

fn main(){
    let f = File::open("hello.txt")?; // Error message: the `?` operator can only be used in a function that returns `Result` or `Option`
\end{lstlisting}

In order to fix this, we can let main() return a result type.

\paragraph*{Fixing our code by making main() return Result}
\begin{lstlisting}
    #![allow(unused)]
    use std::error::Error;
    use std::fs::File;
    
    fn main() -> Result<(), Box<dyn Error>>{ //In the error case we return a "Trait" object, which we will talk about in chap 17 
        let f = File::open("hello.txt")?;
    
        Ok(())
    
    }
\end{lstlisting}

\paragraph*{When should we be using the Result enum and the panic! macro?}

In general we should in default use the Result enum, this prevents the program from crashing, and error propagation, which let's the caller decide what to do with the error.

We should only use the panic! macro in exceptional circumstances, for example circumstances where recovering from the error is impossible or recovering from that state is impossible.

Another appropriate place to allow our code to panic! is in example code. We can use methods like unwrap or expect for brevity, and since there is no context for determinaning with how to deal with errors.

We may also use unwrap or expect in prototype code, in order to get code out quickely in order to test it and then introduce error handling after.

We may also use expect or unwrap in test code.

Lastly, we may use expect or unwrap when we know a call to function will succeed.

\section{Generics}
In the next three sections we will be covering generics, traits and lifetimes. These are all ways to reduce code duplication.

\subsection{A first example}

Say we have a list of numbers and we want to find the largest element, then naively we can write it like this:\begin{lstlisting}
    fn main() {
    let number_list = vec![34, 50, 25, 100, 65];

    let mut largest = number_list[0];

    for number in number_list {
        if number > largest {
            largest = number;
        }
    }

    println!("The largest number is {}", largest); // prints 100
}
\end{lstlisting}

The problem with this code is that if we want to find the largest element of another function, we will have to rewrite the for loop again. An easy fix to this is to put the logic used to find the largest number into another function:
\newpage
\begin{lstlisting}
    fn main() {
    let number_list = vec![34, 50, 25, 100, 65];

    let largest = get_largest(number_list); //Returns 100

    println!("The largest number is {}", largest); 

    let number_list = vec![102, 34, 6000, 89, 54, 2, 43, 8];

    let largest = get_largest(number_list); //Returns 6000
    
    println!("The largest number is {}", largest); 
}


fn get_largest(number_list: Vec<i32>) -> i32{
    let mut largest = number_list[0];
    for number in number_list {
        if number > largest {
            largest = number;
        }
    }
    largest
}
\end{lstlisting}

But what if we want to use the same logic as in our get\_largest function over a slightly different set of arguments. Let say we are looking for the largest character in a vector.

We can use ``generics'' to modify our get\_largest function to be able to take in both a Vec<i32> and Vec<char>


\paragraph*{Using generics to generalise our function}
\begin{lstlisting}
    fn main() {
    let number_list = vec![34, 50, 25, 100, 65];

    let largest = get_largest(number_list); //Returns 100

    println!("The largest number is {}", largest);

    let char_list = vec!['y', 'm', 'a', 'q'];

    let largest = get_largest(char_list); //Returns 'y'
    
    println!("The largest character is {}", largest);
}


fn get_largest<T: PartialOrd + Copy>(list: Vec<T>) -> T{ // Generic types are specified in <> after the function name
    let mut largest = list[0];
    for element in list {
        if element > largest {
            largest = element;
        }
    }
    largest
}
\end{lstlisting}
\begin{remark}
    PartialOrd and Copy are traits. We need to specify them to restrict our function to only accepting types that can be ordered and copied (like ints or char).

    We will talk more about traits in next section.
\end{remark}

\paragraph*{Generic Types in Structs}
\begin{lstlisting}
    struct Point<T, U>{
    x: T,
    y: U, // If we only used one generic, then both x and y would have to be of the same type T
}


fn main() {
    let p1 = Point{x:5, y:10}; // Can pass in two i32
    let p2 = Point{x:5.0, y:10.0}; // Can pass in two f64
    let p3 = Point {x: 5, y:10.0}; // Or can pass in one i32 and one f64 (where i32-> T and f64->U)
}
\end{lstlisting}

We can also use generics in enums, recall the Option and Result enum are implemented using generics.

\begin{lstlisting}
    fn main(){
        enum Option<T>{ // Use only one generic
            Some(T),
            None,
        }

        enum Result<T,E>{ // Two generics, T and E
            Ok(T),
            Err(E),
        }
    }
\end{lstlisting}

\paragraph*{Genercis in Method Definitions}
\begin{lstlisting}
    struct  Point<T>{
    x: T,
    y: T,
}


impl<U> Point<U> { // Note we don't need to use the same name, implentation uses a generic and calls it U.
    fn x(&self) -> &U{
        &self.x
    }
}

impl Point<f64> { // Here the method is only defined for Points that have a type parameter of f64
    fn y(&self) -> f64{
        self.y
    }
}


fn main(){
    let p = Point {x:5, y:10}; // x() is avaliable as a method but not y()
    let p1 = Point {x: 5.0, y:10.0}; // both x() and y() are available.
}
\end{lstlisting}

\paragraph*{A more complex example}
\begin{lstlisting}
    struct  Point<T, U>{
    x: T,
    y: U,
}


impl<T, U> Point<T, U> {
    fn mixup<V,W>(self, other: Point<V,W>) -> Point<T,W>{
        Point{
            x: self.x,
            y: other.y,
        }
    }
}


fn main(){
    let p1 = Point{x: 5, y:10.4};
    let p2 = Point{x:"Hello", y: 'c'};

    let p3 = p1.mixup(p2);

    println!("p3.x = {}, p3.y = {}", p3.x, p3.y); // p3.x = 5, p3.y = c
}
\end{lstlisting}
\newpage
Finally let us talk about performance, generics allow us to reduce duplication without incuring a performance hit:\begin{lstlisting}
    enum Option<T>{
        Some(T),
        None,
    }

    fn main(){
        let integer = Option::Some(5);
        let float = Option::Some(5.0);
    }
\end{lstlisting}
 At compile time Rust will turn the Option enum into two enums one for i32 and one for f64
 \newpage
 \section{Traits}

\begin{definition}
    \textbf{Traits} allow us to define a set methods that are shared across different types. 
\end{definition}
\subsection{Implementations}
\paragraph*{How are Traits implemented?}\begin{lstlisting}
use std::iter::Sum;
pub struct NewsArticle {
    pub headline: String,
    pub author: String,
    pub content: String,
}

 impl Summary for NewsArticle{
    fn summarize_author(&self) -> String { 
        format!("{}", self.author) 
    }
    // Don't need to implement summarize since we will use the default implematation.
 }

pub struct Tweet{
    pub username: String,
    pub content: String, 
    pub reply: bool,
    pub retweet: bool,
}

impl Summary for Tweet{
    fn summarize_author(&self) -> String {// We need to implement summarize_author since the function has no default implementation. 
        format!("@{}", self.username) 
    }

    fn summarize(&self) -> String {
        format!("{}: {}", self.username, self.content)
    }
}

pub trait Summary{ //Defines a shared methods for our types
    fn summarize_author(&self) -> String;
    
    fn summarize(&self) -> String{
        format!("(Read more from {}...)", self.summarize_author()) //Default implementation, if our struct doesn't implement this function it will use this implementation
    }
}
fn main(){
    let tweet = Tweet{
        username: String::from("@user"),
        content: String::from("Hello world"),
        reply: false,
        retweet: false
    };
    let article = NewsArticle{
        author: String::from("The Author"),
        headline: String::from("I wrote an article!"),
        content: String::from("This is my article")
    };
    println!("Tweet summary: {}", tweet.summarize()); 
    println!("Article summary: {}", article.summarize()); 
}
\end{lstlisting}

\paragraph*{This code outputs}\begin{lstlisting}
    Tweet summary: @user: Hello world
Article summary: (Read more from The Author...)
\end{lstlisting}

\newpage
\subsection{Trait Bounds}
\paragraph*{\&impl syntax and trait bound}\begin{lstlisting}
    // Put in previous Implementations of Tweet, NewsArticle, Summary are to be put here

    pub fn notify(item: &impl Summary){ // This function takes in a reference to something that implements summary
        println!("Breaking news! {}", item.summarize());
    }
   

    fn main(){
        \\ Put in the previous defintions of tweet and article
        notify(&article);
    }
\end{lstlisting}
\paragraph*{This code outputs}\begin{lstlisting}
    Breaking news! (Read more from The Author...)
\end{lstlisting}
This above \&impl syntax is syntax sugar for what is called a ``trait bound'' which looks like this:

\paragraph*{Trait Bound}\begin{lstlisting}
    
    // Put in previous Implementations of Tweet, NewsArticle, Summary are to be put here
    pub fn notify<T:Summary>(item: &T){ // Generic that is limited to something that interprets a Summary trait.
        println!("Breaking news! {}", item.summarize());
 } // Does the same as the &impl syntax 
\end{lstlisting}

This syntax is useful if we want our function to take in multiple inputs of the same type:
\paragraph*{Multiple inputs}\begin{lstlisting}
    pub fn notify(item1: &impl Summary, item2: &impl Summary){ // Here item1 and item2 can be anything that implements Summary, but they can also be different from eachother.
        //...
}

     pub fn notify<T:Summary>(item1: &T, item2: &T){ // item1 and item2 are both of the same type &T which can be anything that implements Summary. 
         //...
}
\end{lstlisting}


\paragraph*{Specifying multiple traits and the where clause}\begin{lstlisting}  
   // impl syntax:
   
   
   pub fn notify(item1: &(impl Summary + Display), item2: &impl: Summary){ //item1 is anything that implements both Summary and Display, while item2 is anything that implements Summary
        //...
 }
   
   // //Trait bound syntax
   
 pub fn notify<T:Summary+Display>(item1: &T, item2: &T){
        //....
}
   
   // Specifying multiple trait bounds can hinder readablity, for example:
   
fn some_function<T:Display+Clone, U: Clone + Debug>(t:&T, u:&U) ->i32{....}
   
   
   // To make it more readible we can use the "where"-clause
   
fn some_function<T,U>(t:&T,u:&U) ->i32
        where T:Display+Clone,
              U: Clone+Debug
    {
       ///..
   }
   
\end{lstlisting}

\paragraph*{Trait bounds to conditionally implement methods}\begin{lstlisting}
    struct Pair<T>{
         x: T,
         y: T,
}
    
     impl<T> Pair<T>{ //This implementation block is for any pair struct.
         fn new(x: T, y: T) -> Self{ // Every pair struct will have this method
             Self {x,y}
         }
 }
    
     impl<T: Display + PartialOrd> Pair<T>{ // We use trait bounds to say that T has to implement display and partial order
         fn cmp_display(&self){ // only the struct that, where T implement display and partial order will have this function
             if self.x >= self.y{
                 println!("The largest member is x = {}", self.x);
             } else{
                 println!("The largest member is y = {}", self.y);
             }
         }
     }
    
    
\end{lstlisting}    
\paragraph*{Blanket implementation}\begin{lstlisting}
    
    // We can implement a trait on a type that implements another strait
    
     impl<T:Display> ToString for T{ // We implement the ToString trait on any type that implement Display
         //
     } // We will talk about this later.
\end{lstlisting}
\subsection{Return types}
Now let us talk about return types.
\begin{lstlisting}
    // Put in previous Implementations of Tweet, NewsArticle, Summary are to be put here

fn returns_summarizable() -> impl Summary  {//We return any type that implements the summary trait
    Tweet {
        username: String::from("horse_ebooks"),
        content: String::from(
            "of course, as you probably already know, people",
        ),
        reply: false,
        retweet: false,
    }
} // This is very useful with closures and iterators which we will learn more about later.

// While this function can return any type that implements Summary it has it's limits.  While we can return any type implementing Summary, we can only return one type at a time.

 fn return_bool(switch: bool) ->impl Summary{ // This code does not compile.
     if switch{
         NewsArticle{
             ///
         }
     } else{
         Tweet{
             ///
         }
     }
}

fn main(){
    println!("{}", returns_summarizable().summarize());
}
\end{lstlisting}
\paragraph*{This code outputs}\begin{lstlisting}
    horse_ebooks: of course, as you probably already know, people
\end{lstlisting}



\section{Lifetimes}
\begin{definition}
    \textbf{A dangling reference} is a reference that points to invalid data. Rust does not like dangling references.
\end{definition}
\paragraph*{Dangling referece}\begin{lstlisting}
    fn main() {
    let r;          //--------------+----'a, lifetime of r denoted by 'a
    {                          //   |
        let x = 5; //--+--'b,       |        lifetime of x denoted by 'b
        r = &x;    //--|            |
    }              //--+            |          x dies here.
                                //  |         
    println!("r: {}", r);         //|
}                                   +        r dies here 
\end{lstlisting}
r is a dangling reference, since it is referencing x which was invalidated after it went out of scope.
Rust doesn't let this code complie. It knows at compile that $x$ doesn't live long enough for us to reference it because of the borrow-checker.


\begin{lstlisting}
    fn main() {
    
        let x = 5;          // -------------------+--'b
        let r = &x;         //--+--'a             |
    println!("r: {}", r);   //  |                 |
}                           //--+-----------------+
\end{lstlisting}

When we print $r$ here, $r$ is referencing $x$ whose lifetime is valid at that point, so we don't get any error.

The bottow-checker is able to figure all this out without help. Now we will talk about situations where we do need to help the compliler.

\subsection{Genreric Lifetime annotations}

\paragraph*{Problematic code}\begin{lstlisting}
    fn main() {
    let string1=String::from("abcd");
    let string2 = String::from("xyz");

    let result = longest(string1.as_str(), string2.as_str());
    println!("The longest string is {}", result); // As the borrow checker how would we know that result is not dangling reference?

    fn longest(x:&str, y:&str) -> &str{
        if x.len()> y.len(){
            x
        }else{
            y
        }
    }
}
\end{lstlisting}
longest returns a reference, but we don't know what the lifetime is. First of all x and y can have different lifetimes, secondly we don't know what are their lifetimes.

In order to fix this we need to use generic lifetime annotations.\begin{definition}
    \textbf{Generic lifetime annotations} describe the relationship between lifetimes of different references and how they relate to eachother.
\end{definition}
We call these generic lifetime annotations, ``lifetimes''.

\paragraph*{Using Lifetimes}\begin{lstlisting}
    fn main() {
    let string1=String::from("abcd");
    let string2 = String::from("xyz");
    let result = longest(string1.as_str(), string2.as_str());
    println!("The longest string is {}", result); 
    fn longest<'a>(x:&'a str, y:&'a str) -> &'a str{  // What wer are saying is that the lifetime of the return reference is the same as the smallest lifetime of the argument.
        if x.len()> y.len(){
            x
        }else{
            y
        }
    }
}
\end{lstlisting}

How does the borrow-checker know that result is a valid reference? We just told the borrow checker that 'result' has the lifetime equal to the smallest lifetime passed in. 
So the borrow checker just needs to check that if result is called the smallest lifetime is still valid.

\paragraph*{Example with different lifetimes}\begin{lstlisting}
    fn main() {
    let string1=String::from("abcd");
    
    {
        let string2 = String::from("xyz");

        let result = longest(string1.as_str(), string2.as_str()); //result is valid until the end of string2's lifetime. 
        println!("The longest string is {}", result); 

    } 
}    
   
fn longest<'a>(x:&'a str, y:&'a str) -> &'a str{  
    if x.len()> y.len(){
        x
    }else{
        y
    }
}
\end{lstlisting}

\paragraph*{Error}\begin{lstlisting}
    fn main() {
    let string1=String::from("abcd");
    let result;
    {
        let string2 = String::from("xyz");

        result = longest(string1.as_str(), string2.as_str()); //result only last until string2 dies 
    } 
    println!("The longest string is {}", result); //Error since string2 is not valid, so result isn't
}    
   
fn longest<'a>(x:&'a str, y:&'a str) -> &'a str{  
    if x.len()> y.len(){
        x
    }else{
        y
    }
}
\end{lstlisting}

\paragraph*{If lifetime tied only to x}\begin{lstlisting}
 fn main() {
    let string1=String::from("abcd");
    let result;    
    {
        let string2 = String::from("xyz");
        result = longest(string1.as_str(), string2.as_str());
    } 
   
   println!("The longest string is {}", result); 
    
}   
fn longest<'a>(x:&'a str, y:&str) -> &'a str{  
    x
}
\end{lstlisting}
This code compliles, since the borrow checker just makes sure that result has the same lifetime as string1.

\subsubsection{Structs with lifetime annotations}


\begin{lstlisting}
    struct ImportantExcerpt<'a>{
    part: &'a str,
}

fn main(){
    let novel = String::from("Call me Ishmael, Some years ago....");
    let first_sentence = novel.split('.').next().expect("Could not find sentence");
    let i = ImportantExcerpt{
        part: first_sentence,
    };
}
\end{lstlisting}

Variable i is only valid as long as first\_sentence is in scope, we will get an error if we try to use it after first\_sentence has left scope.

\subsection{Lifetime elision rules}

There are some times when the compiler can determinstically infer the lifetimes annotations by checking the \textbf{three lifetime elision rules}.  

\begin{definition}
    \textbf{Input lifetimes} are the lifetimes of the argument that are passed in
\end{definition}

\begin{definition}
    \textbf{Output lifetime} are the lifetimes fo the arguments returned.
\end{definition}

\begin{definition}
    \textbf{Three rules:}

    \begin{enumerate}
        \item Each parameter that is a reference gets its own lifetime paramater
        \item If there is exactly one input lifetime parameter, that lifetime is assigned to all output lifetime parameters
        \item If there are multiple input lifetime parameters, but one of them is \&self or \&mut self the lifetime of self is assigned to all output lifetime paramaters.
    \end{enumerate}
\end{definition}
THe compiler will try to follow these three rules, if it can't determine the lifetimes at the end of these three rules, we will have to manually specify them.

\begin{lstlisting}
    struct ImportantExcerpt<'a>{
    part: &'a str,
}

impl<'a> ImportantExcerpt<'a>{
    fn return_part(&self, announcement: &str) -> &str{
        println!("Attenetion please: {15 Hours a Day of Mathematics Self-Study
        28,988 views
        Jun 14, 2022
        1.3K
        Dislike
        Share
        Thanks
        Clip
        Save
        
\paragraph*{Example combining generics, traits and lifetimes.}\begin{lstlisting}
    use std::fmt::Display;

fn longest_with_an_announcement<'a, T>(
    x: &'a str,
    y: &'a str, //Need to specify lifetime since more than 1 input.
    ann: T, //Generic
) ->&'a str
where
    T:Display, //Triat bound limit T to only those that implement Display
{
    println!("Announcement! {}", ann);
    if x.len() > y.len(){
        x
    }else {
        y
    }
}

fn main(){
    let announcement = String::from("Grand finale");
    let x = "we did generics, traits and lifetimes";
    let y = "how fun!!!!";
    let result = longest_with_an_announcement(x, y, announcement);
    println!("These past sections {}, {}", result, y);
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
Announcement! Grand finale
These past sections we did generics, traits and lifetimes, how fun!!!!
\end{lstlisting}

\section{Testing}

\subsection{Writing tests}

Why do we want to write tests? Rust checks that our code works correctly with borrow checker and checking types etc.. But it doesn't check that our functions are 
working in the way we intend them to. Which is why we need to make tests. 

\

In Rust functions are tests if they have the \#[test] attribute. In order to run our tests, we type in cargo test in the terminal. Our test will fail when something inside the test function panics.
\newpage 
\paragraph*{Testing our Rectangle struct}\begin{lstlisting}
    #[derive(Debug)]
struct Rectangle{
    width: u32,
    height: u32,
}

impl Rectangle{
    fn can_hold(&self, other: &Rectangle) -> bool{
        self.width>other.width&&self.height>other.height
    }
}

#[cfg(test)]
mod tests {
    use super::*; // We need to bring our product code into scope

    #[test]
    fn larger_can_hold_smaller(){
        let larger = Rectangle{
            width: 8,
            height: 7,
        };
        let smaller = Rectangle{
            width: 5,
            height:1,
        };

        assert!(larger.can_hold(&smaller));
    }
    #[test]
    fn smaller_cannot_hold_larger(){
        let larger = Rectangle{
            width: 8,
            height: 7,
        };
        let smaller = Rectangle{
            width: 5,
            height:1,
        };

        assert!(!smaller.can_hold(&larger));
    }
}
\end{lstlisting}
In this case our two tests pass, if we changed a `>' into a `<' in the implematation of can\_hold, out larger\_can\_hold\_smaller test would fail.

\paragraph*{assert equal and not equal}\begin{lstlisting}
    pub fn add_two(a:i32)->i32{
    a+3
}
#[cfg(test)]
mod tests {
   use super::*; 
    #[test]
    fn it_adds_two(){
        assert_ne!(4,add_two(2)); // passes if 4 not equal to add_two(2)
    }
    fn it_adds_three(){
        assert_eq!(5,add_two(2)); // passes if 5 is equal to add_two(2)
    }
}
\end{lstlisting}
Both paramaters passed in assert\_eq! and assert\_ne! must implement the PartialEq and Debug traits.
\paragraph*{Custom failure message}\begin{lstlisting}
    use std::fmt::format;

pub fn greeting(name: &str) ->String{
    format!("Hello")
}
#[cfg(test)]
mod tests {
use super::*; 
    #[test]
    fn greeting_contains_name(){
        let result = greeting("Carol");
        assert!(
            result.contains("Carol"),
            "Greeting did not contain name, value was {}", result // Custom failure message
        );
    }
}
\end{lstlisting}

\paragraph*{Failure message}\begin{lstlisting}
    thread 'tests::greeting_contains_name' panicked at 'Greeting did not contain name, value was Hello'
\end{lstlisting}

\paragraph*{Asserting a function that panics}\begin{lstlisting}
    pub struct  Guess{
    value: i32,
}


impl Guess{
    pub fn new(value:i32) -> Guess{
        if value < 1 || value >100{
            panic!("Guess value must be between 1 and 100, got {}.", value);  
        }

        Guess {value}
    }
}

#[cfg(test)]
mod tests {
use super::*; 
    #[test]
    #[should_panic] // Asserts that the test panics
    fn greater_than_100(){
        Guess::new(200);
    }
}
\end{lstlisting}

Since we have the \#[should\_panic] our tests pass.

\paragraph*{Many panics}\begin{lstlisting}
    pub struct  Guess{
    value: i32,
}


impl Guess{
    pub fn new(value:i32) -> Guess{
        if value < 1{
            panic!("Guess value must be greater than or equal to 1, got {}", value);
        }else if value > 100{
            panic!("Guess value must be less than or equal to 100, got {},", value)
        }

        Guess {value}
    }
}

#[cfg(test)]
mod tests {
use super::*; 
    #[test]
    #[should_panic(expected = "Guess value must be less than or equal to 100")]
    fn greater_than_100(){
        Guess::new(200);
    }
}
\end{lstlisting}

Here our test passes only if when our failure message is what we have expected. If we change Guess::new{(200)} to Guess::new{(-2)} our test fails.


\paragraph*{Tests that return a result type}\begin{lstlisting}
    #[cfg(test)]
mod tests {
    #[test]
    fn it_works() -> Result<(), String>{
        if 2+2 == 4{
            Ok(())
        } else {
            Err(String::from("two plus two not equal to four!"))
        }
    }
}
\end{lstlisting}
\subsection{Running tests and organising into unit tests and integration test}
\subsubsection{Configuring tests}
By default all test are run in parallel in a seperated thread and all output is capture and not printed to screen.


There are two sets of command line options, one sets goes to the cargo test command and the other to the resulting test binary.

If we want to figure out which option we could pass to the cargo test command we type:\begin{lstlisting}
    cargo test --help
\end{lstlisting}


And to figure out which command we can pass to our resulting test binary we type:\begin{lstlisting}
    cargo test -- --help
\end{lstlisting}

\begin{example}
    If we want to run tests serially we can set the option like so:\begin{lstlisting}
        cargo test -- --test-threads=1
    \end{lstlisting}
\end{example}

By default standard output is captured for passing test, so will only see printed output for failing tests. We can change that by using this command:
\paragraph{Showing output}\begin{lstlisting}
    cargo test -- --show-output
\end{lstlisting}

\begin{lstlisting}
    fn prints_and_returns_10(a: i32) -> i32{
        println!("I got the value {}", a);
        10
}
    #[cfg(test)]
    mod tests {
        use super::*;
    
        #[test]
        fn this_test_will_pass(){
            let value = prints_and_returns_10(4); // This code will print out if we use above command but not by default
            assert_eq!(10,value);
        }
    
    
        #[test]
        fn this_test_will_fail(){
            let value = prints_and_returns_10(8); // This code will always print since the test fails
            assert_eq!(5, value);
        }
    }       
\end{lstlisting}

\paragraph{Running a subset of tests}\begin{lstlisting}
    pub fn add_two(a:i32)->i32{
    a+2
}
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn add_two_and_two(){
        assert_eq!(4, add_two(2));
    }
   
   #[test]
    fn add_three_and_two(){
        assert_eq!(5, add_two(3));
    }

    #[test]
    fn one_hundred(){
        assert_eq!(102, add_two(100));
    }

}
\end{lstlisting}

In this example we can:\begin{itemize}
    \item Only run a specific test by specifiying it's name:\begin{lstlisting}
        cargo test one_hundred 
    \end{lstlisting}
    \item Run tests with a common part of their name:\begin{lstlisting}
        cargo test add
    \end{lstlisting}
    This will run tests for add\_two\_and\_two and add\_three\_and\_two
    \item Run tests by specifying the module:\begin{lstlisting}
        cargo test tests::
    \end{lstlisting}
    Which will run all three tests in the module. 
\end{itemize}

\paragraph{Ignoring tests}\begin{lstlisting}
    #[cfg(test)]
mod tests {
    #[test]
    fn it_works(){
        assert_eq!(2+2,4);
    }

    #[test]
    #[ignore] // This makes it so that we ignore this tests when we run cargo test
    fn expensive_test(){
        // code that takes an hour to run
    }
}
\end{lstlisting}


To run ignored test\begin{lstlisting}
    cargo test -- --ignored
\end{lstlisting}

\subsubsection{Test organisation}
\begin{definition}
    The Rust community puts tests in two main categories:
    \begin{itemize}
        \item Unit tests, small, focused, tests one module in isolation and can tests private interfaces
        \item Integration tests, external to library so tests the public interface of library.
    \end{itemize}    
Up until now we have been writing unit tests, they live in the same file as our product code. Integration tests live in a folder called tests at the root of our project.
\end{definition}

\paragraph*{Unit test}\begin{lstlisting}
    pub fn add_two(a:i32)->i32{
    internal_adder(a,2)
}

fn internal_adder(a:i32, b:i32) ->i32{
    a+b
}

// Convention that in the same file as our product code we have a module named test, that runs tests.
#[cfg(test)] // This makes it so that we only compile the bellow code when we run test.
mod tests { //Test module, holds our test.
    use super::*;

    #[test]
    fn internal(){
        assert_eq!(4, internal_adder(2, 2)); // internal_adder is private but we can call it since in rust, child modules can access anything in parent module including private fields.
    }
}
\end{lstlisting}

\paragraph*{Integration Test}\begin{lstlisting}
//In the test folder in the root file, file path is adder/tests/integration_test.rs
use adder;

#[test]
fn it_adds_two(){
    assert_eq!(4, adder::add_two(2)); // Need to call the public API, can't call the inner adder function
}
\end{lstlisting}
If we want to run just our integration test we can type:\begin{lstlisting}
    cargo test --test integration_test
\end{lstlisting}

Because every file in test directory is treated like a seperate crate, it can cause unexpected behaviour.

Assume we have multiple integration test files and want to share some code between them. If we try to create a new file called common.rs where we will store the common code between the integration tests. Rust will treat it like another integration test file, which is not what we want.

To get the behaviour we want let us create a folder in our tests directory, called common and create a file in it called mod.rs and put in the shared code in this file.

This words since files in subdirectories of our test folder do not get compiled as crates. Furthremore, our shared code is now in a module that can be used by the other integration test files.

\paragraph*{Using common code for integrated tests}\begin{lstlisting}
    use adder;

mod common; //Module declaration it will look content of module in either a file called common.rs or a folder called common with a file called mod.rs 

#[test]
fn it_adds_two(){
    common::setup(); //Using the module here 
    assert_eq!(4, adder::add_two(2));
\end{lstlisting}
\paragraph*{mod.rs file}\begin{lstlisting}
// Path /adder/tests/common/mod.rs
    pub fn setup(){
    // set up code
}
\end{lstlisting}

Note we cannot directly test binary crates with integration tests, which is why it is common to see a binary crate that is a thin wrapper around a library crate, so that we can test the library crate with integration tests.

\section{First Rust Project: Building a Command Line Program minigrep}
We will use what we have learned so far to create a command line program which will is a simple verson of the tool grep(which allows us to search for a string in a file). We will call this program ``minigrep''. 


\subsection{Creating the program}

\paragraph*{First using args method to read arguments passed in command line}\begin{lstlisting}
use std::env;
fn main() {
    let args: Vec<String> = env::args().collect(); 
    println!("{:?}", args);
}
\end{lstlisting}
The {args}() function gives us an iterator over the argumens passed by our progam, and {collect}() turns this iterator into a collection we can use, in this case a vector of strings.

\paragraph*{Passing in arguments}\begin{lstlisting}
    // Passing the arguments needle and haystack:
    cargo run needle haystack

    // Our code prints out 
    ["target/debug/minigrep", "needle", "haystack"]
\end{lstlisting}
By default we always get the path to our binary passed. In this case, though we don't care about the binary path and only the query and the file name.
\paragraph*{Isolating query and filename}\begin{lstlisting}
    use std::env;
fn main() {
    let args: Vec<String> = env::args().collect(); 
    let query = &args[1];
    let filename = &args[2];
    
    println!("Searching for {}", query);
    println!("In file {}", filename);
}
\end{lstlisting}
Next step is to read in file.

\paragraph*{Read from file}\begin{lstlisting}
use std::env;
use std::fs;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    let query = &args[1];
    let filename = &args[2];
    
    println!("Searching for {}", query);
    println!("In file {}", filename);

    let contents = fs::read_to_string(filename)
        .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);
}
\end{lstlisting}

\paragraph*{Running this program with example file: poem.txt}\begin{lstlisting}
\\ Cargo run on the file poem.txt:
cargo run the poem.txt

\\Output of our program:
Searching for the
In file poem.txt
With text:
I'm nobody! Who are you?
Are you nobody, too?
Then there's a pair of us - don't tell!
They'd banish us, you know.

How dreary to be somebody!
How public, like a frog
To tell your name the livelong day
To an admiring bog!
\end{lstlisting}


We can read a file, now let us improve our program.
\subsection{First problem: Extracting out our code}

main.rs has too many responsiblities. What we should do is create a library crate and have our binary crate call funcitons from the library crate.

\paragraph*{Extracting out the argument parsing logic}\begin{lstlisting}
    use std::env;
use std::fs;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let (query, filename) = parse_config(&args);

    println!("Searching for {}", query);
    println!("In file {}", filename);

    let contents = fs::read_to_string(filename)
    .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);
}

fn parse_config(args: &[String]) -> (&str,&str){
    let query = &args[1];
    let filename = &args[2];
    (query, filename)
}
\end{lstlisting}

Now our tuple, doesn't tell us how are two values query and filename are related. So let us create a struct to make this relation more explicit.

\paragraph*{Config struct}\begin{lstlisting}
    use std::env;
use std::fs;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= parse_config(&args);

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    let contents = fs::read_to_string(config.filename)
    .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);
}

struct Config{
    query: String,
    filename: String,
}

fn parse_config(args: &[String]) -> Config{
    let query = args[1].clone(); // Use the clone method since we don't want to take ownership
    let filename = args[2].clone();
    
    Config {query, filename}
} 
\end{lstlisting}

Note this is not the most elegant way of doing this, since we are cloning our string. But better way of doing this would require us to use lifetimes, so while this is not efficient it is simpler. We will look at how to handle this more efficiently later.

There is more room for improvement, the parse\_config is very closely related to our Config struct, so let us make this relationship more explicit by turning by putting it in an impl block.
\paragraph*{Constructor function}\begin{lstlisting}
    use std::env;
use std::fs;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args);

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    let contents = fs::read_to_string(config.filename)
    .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);
}

struct Config{
    query: String,
    filename: String,
}

impl Config{
    fn new(args: &[String]) -> Config{ // Calling this function new is convention for constructor functions.
        let query = args[1].clone();
        let filename = args[2].clone();
        
        Config {query, filename}
    } 
}
\end{lstlisting}
\subsection{Second problem: Error handling}

If we call our program and don't pass in enough arguments we don't get a useful error message.\begin{lstlisting}
    thread 'main' panicked at 'index out of bounds: the len is 1 but the index is 1', src/main.rs:25:21
\end{lstlisting}

Let make this error message less confusing, by changing our Config::new function:
\begin{lstlisting}
    fn new(args: &[String]) -> Config{
        if args.len()<3{
            panic!("not enough arguments");
        }

        let query = args[1].clone();
        let filename = args[2].clone();
        
        Config {query, filename}
    }     
\end{lstlisting}

Now the error message is\begin{lstlisting}
    thread 'main' panicked at 'not enough arguments', src/main.rs:26:13
\end{lstlisting}

Now this error message also has a lot of noise, since we are using panic! Let us fix this with the Result type.

\paragraph*{Using the Resut type for error handling}\begin{lstlisting}
    use std::env;
use std::fs;
use std::process; // Let's us exit program without panicking.

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args).unwrap_or_else(|err|{
        println!("Problem parsing arguments {}", err);
        process::exit(1);
    });

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    let contents = fs::read_to_string(config.filename)
    .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);
}

struct Config{
    query: String,
    filename: String,
}

impl Config{
    fn new(args: &[String]) -> Result<Config, &str>{
        if args.len()<3{
            return Err("not enough arguments");
        }

        let query = args[1].clone();
        let filename = args[2].clone();
        
            Ok(Config {query, filename})
    } 
}
\end{lstlisting}

Note the unwrap\_or\_else() is a function that takes in a closure, In the Ok case it returns the value stored in Ok, and in the Err case it will execute the closure passing it Err.
We will learn more about closures later.

Now the error message is \begin{lstlisting}
    Problem parsing arguments not enough arguments
\end{lstlisting}

\subsection{Extracting some more logic from main.rs}\begin{lstlisting}
    use std::env;
use std::fs;
use std::process;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args).unwrap_or_else(|err|{
        println!("Problem parsing arguments {}", err);
        process::exit(1);
    });

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    run(config);

}

fn run(config: Config){
    let contents = fs::read_to_string(config.filename)
    .expect("Something went wrong reading the file");

    println!("With text:\n{}", contents);

}
// ...Config struct and impl here...
\end{lstlisting}

Now let us treat error handling in our run function so that we don't have to call {expect}() and panic if we get an error.
\paragraph*{Error handling}\begin{lstlisting}
    use std::env;
use std::fs;
use std::process;
use std::error::Error; // Im,port the Error type

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args).unwrap_or_else(|err|{
        println!("Problem parsing arguments {}", err);
        process::exit(1);
    });

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    if let Err(e) = run(config){
        println!("Application error: {}", e); //If run returns error then we execture this code block.
        process::exit(1);
    }

}

fn run(config: Config) -> Result<(), Box<dyn Error>>{
    let contents = fs::read_to_string(config.filename)?; //If read_to_sting returns an Error type, that Error type will be automatically returned from run(). 

    println!("With text:\n{}", contents);

    Ok(())

}

// Put config struct and impl block here.
\end{lstlisting}

\subsection{Extracting functions into a library crate}
Our main.rs code is started to get bloated so let us extract run function and Confic struct with impl block into library crate.

\paragraph*{lib.rs}\begin{lstlisting}
    use std::fs;
use std::error::Error;



pub fn run(config: Config) -> Result<(), Box<dyn Error>>{ // Need to make functions and structs that we want to use ourside this file public 
    let contents = fs::read_to_string(config.filename)?;  

    println!("With text:\n{}", contents);

    Ok(())

}

pub struct Config{
    pub query: String,
    pub filename: String,
}

impl Config{
    pub fn new(args: &[String]) -> Result<Config, &str>{
        if args.len()<3{
            return Err("not enough arguments");
        }

        let query = args[1].clone();
        let filename = args[2].clone();
        
            Ok(Config {query, filename})
    } 
}
\end{lstlisting}

\paragraph*{main.rs}\begin{lstlisting}
    use std::env;
use std::process;

use minigrep::Config;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args).unwrap_or_else(|err|{
        println!("Problem parsing arguments {}", err);
        process::exit(1);
    });

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    if let Err(e) = minigrep::run(config){
        println!("Application error: {}", e); //If run returns error then we execture this code block.
        process::exit(1);
    }

}
\end{lstlisting}

\subsection{Test Driven Development}
Want we want to do is write a test that fails, then implement the logic that would make the test pass and then if neccesary refactor our code and make sure our test still passes.

Currently our program just prints out the contents of our file, but we want our program to only print out lines in our file that include our query. To do this we want to create a function called search. But before creating that function, let us write a failing test.
\paragraph*{Our test function}\begin{lstlisting}
    #[cfg(test)]
mod test{
    use super::*;

    #[test]
    fn one_result(){
        let query = "duct";
        let contents = "\
Rust
safe, fast, productive.
Pick three";
        assert_eq!(vec!["safe, fast, productive"], search(query, contents)); \\Search function doesn't exits yet
    }
}
\end{lstlisting}

Now let us first define the search funtion, returning an empty vector:\begin{lstlisting}
    pub fn search<'a>(query: &str, contents: &'a str) -> Vec<&'a str>{// Recall we need to put in lifetimes
    vec![]
}
\end{lstlisting}

As expected our test will fail, since we returned an empty string. Now let us modify the search function to make this test pass.

\paragraph*{Working search function}\begin{lstlisting}
    pub fn search<'a>(query: &str, contents: &'a str) -> Vec<&'a str>{// Recall we need to put in lifetimes
    let mut results = Vec::new(); // Create our results vector, making it mutable.
    for line in contents.lines(){  // loop over the lines in our content str
        if line.contains(query){
            results.push(line); // push line in resutls if it contains he query 
        }
    }
    results
}
\end{lstlisting}

Now let us modify our run function to make use of the search function.

\paragraph*{new run function}\begin{lstlisting}
    pub fn run(config: Config) -> Result<(), Box<dyn Error>>{
    let contents = fs::read_to_string(config.filename)?;  

        for line in search(&config.query,&contents){
                println!("{}", line);
        }

    Ok(())
}
\end{lstlisting}

\paragraph*{Output of our program with query: frog}\begin{lstlisting}
Searching for frog
In file poem.txt
How public, like a frog
\end{lstlisting}

\paragraph*{Output of our program with query: dog}\begin{lstlisting}
    Searching for dog
    In file poem.txt
\end{lstlisting}
\subsubsection{Improving our program with environment variables}
Now our program is done but we can improve it. Currently our search logic is search sensitive, so let us give it the option to do case insensitive searching with environment variables.
 

First we add in a failing test
\paragraph*{Creating our tests}\begin{lstlisting}
#[cfg(test)]
mod test{
    use super::*;

    #[test]
    fn case_sensitive(){
        let query = "duct";
        let contents = "\
Rust
safe, fast, productive.
Pick three
Duct tape.";
        assert_eq!(vec!["safe, fast, productive."], search(query, contents));
    }

    #[test]
    fn case_insensitive() {
        let query = "rUsT";
        let contents = "\
Rust:
safe, fast, productive.
Pick three.
Trust me.";

        assert_eq!(
            vec!["Rust:", "Trust me."],
            search_case_insensitive(query, contents)
        );
    }
}
\end{lstlisting}
\paragraph*{Creating our failling function}\begin{lstlisting}
    pub fn search_case_insensitive<'a>(
    query: &str,
    contents: &'a str,
) -> Vec<&'a str>{
    vec![]
}
\end{lstlisting}
\paragraph*{Making this test pass}\begin{lstlisting}
    pub fn search_case_insensitive<'a>(
    query: &str,
    contents: &'a str, 
) -> Vec<&'a str>{
    let query = query.to_lowercase(); // Note to_lowercase() returns a new string, so we are not modifying strings.
    let mut results = Vec::new();
    for line in contents.lines(){
        if line.to_lowercase().contains(&query){
            results.push(line);  
        }
    }
    results
}
\end{lstlisting}

Now we will modify our struct to tell us when we want our search to be case sensitive or not, and we will use environment variables for this.

\paragraph*{Environment variables}\begin{lstlisting}
    pub fn run(config: Config) -> Result<(), Box<dyn Error>>{
    let contents = fs::read_to_string(config.filename)?; 
    
    let results = if config.case_sensitive{
        search(&config.query, &contents)
    }else{
        search_case_insensitive(&config.query, &contents)
    };

    for line in results{
            println!("{}", line);
    }

    Ok(())
}

pub struct Config{
    pub query: String,
    pub filename: String,
    pub case_sensitive: bool,
}

impl Config{
    pub fn new(args: &[String]) -> Result<Config, &str>{
        if args.len()<3{
            return Err("not enough arguments");
        }

        let query = args[1].clone();
        let filename = args[2].clone();
        
        let case_sensitive = env::var("CASE_INSENSITIVE").is_err(); // Takes in a key to environment and returns Result, if the key exists and is set the Result will be Ok containing set value, otherwise the Result will be an error
        // .is_err() returns a boolean. If Result was Ok it returns true, otherwise it returns false.
        
        Ok(Config {query, filename, case_sensitive})
    } 
}
\end{lstlisting}

Now if we run our code normally:

\paragraph*{cargo run to poem.txt}\begin{lstlisting}
Searching for to
In file poem.txt
Are you nobody, too?
How dreary to be somebody!
\end{lstlisting}

Now set CASE\_INSENSITIVE to true:\begin{lstlisting}
    export CASE_INSENSITIVE=true
\end{lstlisting}
\paragraph*{cargo run to poem.txt}\begin{lstlisting}
    Searching for to
    In file poem.txt
    Are you nobody, too?
    How dreary to be somebody!
    To tell your name the livelong day
    To an admiring bog!
\end{lstlisting}
    \subsubsection{Standard Error}
Command line programs our expected to send errors to Standard Error stream and not Standard output. Since if a user wants to send output stream to a file they will still send errors to screen,

Since now if we send our output stream into a file this is what happens:

\paragraph*{cargo run > output.txt}\begin{lstlisting}
    Problem parsing arguments not enough arguments
\end{lstlisting}

Our output.txt file contains our error message. Let us fix this:

\paragraph*{eprintln!}\begin{lstlisting}
    use std::env;
use std::process;

use minigrep::Config;

fn main() {
    let args: Vec<String> = env::args().collect(); 
    
    let config= Config::new(&args).unwrap_or_else(|err|{
        eprintln!("Problem parsing arguments {}", err); // eprintln! prints to the standard error stream 
        process::exit(1);
    });

    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);

    if let Err(e) = minigrep::run(config){
        eprintln!("Application error: {}", e);
        process::exit(1);
    }
}
\end{lstlisting}

Now if we do cargo run > output.txt we get the ``Problem parsing arguments not enough arguments'' error message in the terminal and the output.txt file is empty since there is no output.

\paragraph*{cargo run to poem.txt > output.txt}\begin{lstlisting}
    Searching for to
In file poem.txt
Are you nobody, too?
How dreary to be somebody!

\end{lstlisting} 
This is our output.txt file when we run our program without errors.

\section{Closures}
\begin{definition}
    \textbf{Closures} are like functions but they don't have names. They can be stored in variables or passed in as parameters of a function.
\end{definition}
We don't have to annotate the type of input and output values, the compiler is able to determine the types. As closures are usually short and used in a narrow context. But closures can only have one type infered by the compiler.

\


In order to define structs, enums or function parameters that use closures we need to use generics and trait bounds.

\paragraph*{Struct containing closure}\begin{lstlisting}
    struct Cacher<T>
where 
    T: Fn(u32)->u32, // Any function that takes in an u32 and returns a u32
{
    calculation: T, 
    value: Option<u32>,
}
\end{lstlisting}


\paragraph*{Closuures can't have many types infered for each parameters}\begin{lstlisting}
    let example_closure = |x| x;
    let s = example_closure(String::from("hello")); // Compiler infers that the example closure takes in a string and outputs a string.
    let n = example_closure(5); //Error expected a string but got an integer. 
\end{lstlisting}

\begin{example}
    In this example, let us say that we are working on the backend of a fitness app, which makes workout plans based on specification by the user.
    We will simulate a function that makes an expensive calculation, and we will simulate the code that will create the workout. 

    \begin{lstlisting}
        use std::thread;
use std::time::Duration;

fn simulated_expensive_calculation(intensity: u32) -> u32{
    println!("calculating slowly....");
    thread::sleep(Duration::from_secs(2));
    intensity
}

fn main(){
    let simulated_intensity = 10;
    let simulated_randon_number = 7;

    generate_worlout(simulated_intensity, simulated_randon_number);
}

fn generate_worlout(intensity: u32, random_number: u32){
    if intensity < 25{
        println!(
            "Today, do {} pushups!", 
            simulated_expensive_calculation(intensity)
        );
        println!(
            "Today, do {} situps!", 
            simulated_expensive_calculation(intensity)
        );
    } else {
        if random_number == 3{
            println!("Take a break today! Remember to stay hydrated!");
        } else {
            println!(
                "Today, run for {} minutes",
                simulated_expensive_calculation(intensity)
            );
        }
    }
}
    \end{lstlisting}

This code works, but can use some refactoring. Since we are calling our expensive function in multiple places, if we change how this function is called we will have to change all the callsites. Furthermore we call our function multiple times when we don't need to, for example in the first ``if block'' we call it twice when we only need to call 
it once and pass in the return value in the print statements.
\begin{lstlisting}
    fn generate_worlout(intensity: u32, random_number: u32){
    let expensive_result = simulated_expensive_calculation(intensity);
    if intensity < 25{
        println!(
            "Today, do {} pushups!", 
            expensive_result
        );
        println!(
            "Today, do {} situps!", 
            expensive_result
        );
    } else {
        if random_number == 3{
            println!("Take a break today! Remember to stay hydrated!");
        } else {
            println!(
                "Today, run for {} minutes",
                expensive_result
            );
        }
    }
}
\end{lstlisting}

But notice we still call our expensive function when we may not need it (when intensity > 25 and the random number is 3). Let us fix this with closures.

\paragraph*{Refactoring our function with Cacher}\begin{lstlisting}
    
struct Cacher<T>
where 
    T: Fn(u32)->u32, 
{
    calculation: T, 
    value: Option<u32>,
}

impl<T> Cacher<T>where 
T: Fn(u32)->u32, 
{
    fn new(calculation: T) -> Cacher<T>{
        Cacher { 
            calculation, 
            value:None,
        }
    }

    fn value(&mut self, arg: u32)->u32{
        match self.value{
            Some(v) => v,
            None =>{
                let v = (self.calculation)(arg);
                self.value = Some(v);
                v
            }
        }
    }
}


fn generate_worlout(intensity: u32, random_number: u32){
    let mut cached_result = Cacher::new(|num|{ 
        println!("calculating slowly....");
        thread::sleep(Duration::from_secs(2));
        num
    });
    if intensity < 25{
        println!(
            "Today, do {} pushups!", 
            cached_result.value(intensity) // Call our expensive operation here
        );
        println!(
            "Today, do {} situps!", 
            cached_result.value(intensity) // Don't call the expensive operation here, since the value was already stored.
        );
    } else {
        if random_number == 3{
            println!("Take a break today! Remember to stay hydrated!");
        } else {
            println!(
                "Today, run for {} minutes",
                cached_result.value(intensity)
            );
        }
    }
}
\end{lstlisting}
We might want to use our cacher in different contexts, but there are two problems prevemt us from doing this:\begin{enumerate}
    \item Calling our value method will return the same value even if we input a different arg parameter. So we need to cache a different value for each of argument being passed in. We can fix this implematation by storing our values in a Hashmap. The keys are the arguments passed in and the values are the result of the expensive calculation with that argument pass in.
    \item  Another problem is that we are using hard coded types, we are saying that our program must take in integers and output integers. We can fix this by using generics.
\end{enumerate}
\end{example}

\subsection{Capturing environment with closures}

Unlike function, closures have access to variables in the scope where the closure is defined. For example:\begin{lstlisting}
    fn main(){
        let x = 4;

        let equal_to_x = |z| z == x; // Even though x is defined outside of our closure our function still has access.

        let y = 4;

        assert!(equal_to_x(y));
    }
\end{lstlisting}

Now what happens if we change closure to function?

\begin{lstlisting}
fn main(){
    let x = 4;

    fn equal_to_x(z: i32) -> bool {
        z == x //Error: can't capture dynamic environment in a fn item use the `|| { ... }` closure form instead
    }


    let y = 4;

    assert!(equal_to_x(y));
}
\end{lstlisting}

Since closure can capture environment they need to use extra memory to store that context. Since function don't capture their environment they don't need that overhead.

Closure capture their environment in three ways, which correpsond to the three ways a function take parameters\begin{enumerate}
    \item Taking Ownership
    \item Borrowing mutably
    \item Borrowing immutably 
\end{enumerate}

These three ways are encoded in the function traits: \begin{enumerate}
    \item FnOnce, FnOnce takes ownership of the variables inside the closures environment. Since closures can't take ownership of the same variables more than once, these closures can only be called once.
    \item FnMut, Mutably borrows values.
    \item Fn, Immutably borrows values.
\end{enumerate}

Rust infers which of these traits to use when we create a closure based on how we use the values inside the closures environment. 

But we can, force the closure to take ownership of the values it uses inside it's environment by using the move keyword.\begin{lstlisting}
    fn main(){
        let x = vec![1,2,3];

        let equal_to_x = move |z| z == x; // Closure takes ownership of x

        println!("Can't use x here: {:?}", x); // Get error here since we are using a borrowed value after it has been moved.

        let y = vec![1,2,3];

        assert!(equal_to_x(y));
    }

\end{lstlisting}


\section{Iterators}
\begin{definition}
    The \textbf{Iterator pattern} allows us the iterate over a sequence regardless how the sequence is stored (arrays, vectors, maps, custom data structures). Iterator encapsulates the logic of how to iterate over these structures.
\end{definition}

\paragraph*{Iterator over vector}\begin{lstlisting}
    fn main() {
    let v1 = vec![1,2,3];
    let v1_iter = v1.iter();

    for value in v1_iter{
        println!("Got {}", value);
    }
}
\end{lstlisting}
\paragraph*{Output}\begin{lstlisting}
Got 1
Got 2
Got 3
\end{lstlisting}

\subsection{Iterator trait}
How do iterators work? All iterators implement the iterator trait\begin{lstlisting}
    pub trait Iterator{
        type Item; // associated type
        fn next(&mut self) -> Option<Self::Item>;

        // methods with default implematation elided
    }
\end{lstlisting}

So we only need to implememnt the next method which returns the next item in the iteration wrapped in Some and when we reach the end it returns None.

\paragraph*{Test example}\begin{lstlisting}
#[test]
fn iterator_demonstration(){
    let v1 = vec![1,2,3];
    
    let mut v1_iter = v1.iter();
    
    // .iter immutatable reference
    // .iter_mut mutable reference
    // into_iter to own types
    
    assert_eq!(v1_iter.next(), Some(&1));
    assert_eq!(v1_iter.next(), Some(&2));
    assert_eq!(v1_iter.next(), Some(&3));
    assert_eq!(v1_iter.next(), None);
    }
\end{lstlisting}


\begin{definition}
    There are two types of methods on iterators\begin{enumerate}
        \item \textbf{Adaptators} they take in an iterator and return another iterator
        \item \textbf{Consumer} they take in a iterator and returns another type.  
    \end{enumerate}
\end{definition}


\paragraph*{The consumer method, sum}\begin{lstlisting}
#[test]
fn iterator_sum(){
    let v1 = vec![1,2,3];

    let v1_iter = v1.iter();

    let total: i32 = v1_iter.sum();

    assert_eq!(total,6);
}
\end{lstlisting}

\paragraph*{The adaptor method, map}\begin{lstlisting}
    fn main() {
    let v1: Vec<i32> = vec![1,2,3];
    v1.iter().map(|x| x+1); // map takes in a closure and applies it to the elements of iterator
}
\end{lstlisting}
This returns a warning, in Rust iterators are lazy and do nothing unless consumed. Let us use the consumer method collect which takes our iterator and transformes it into a collection. 

\paragraph*{Collect}\begin{lstlisting}
    fn main() {
    let v1: Vec<i32> = vec![1,2,3];
    let v2: Vec<_> = v1.iter().map(|x| x+1).collect();

    assert_eq!(v2,vec![2,3,4]); // true
}
\end{lstlisting}

\paragraph*{Example}\begin{lstlisting}
    #[derive(PartialEq,Debug)]
struct Shoe{
    size: u32,
    style: String,
}

fn shoes_in_my_size(shoes: Vec<Shoe>, shoe_size: u32) -> Vec<Shoe>{
    shoes.into_iter().filter(|s| s.size == shoe_size).collect()
    // into_iter -> create an iterator that takes ownership
    // filter takes in closure and creates a new iterator, with only the elements that return true when passed into the closure
    // collect creates vector of shoe.
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn filters_by_size() {
        let shoes = vec![
            Shoe {
                size: 10,
                style: String::from("sneaker"),
            },
            Shoe {
                size: 13,
                style: String::from("sandal"),
            },
            Shoe {
                size: 10,
                style: String::from("boot"),
            },
        ];

        let in_my_size = shoes_in_my_size(shoes, 10);

        assert_eq!(
            in_my_size,
            vec![
                Shoe {
                    size: 10,
                    style: String::from("sneaker")
                },
                Shoe {
                    size: 10,
                    style: String::from("boot")
                },
            ]
        );
    }
}
\end{lstlisting}

\subsection{Creating our own iterators}

\paragraph*{Iterator on Counter Struct}\begin{lstlisting}
    struct Counter{
    count: u32
}

impl Counter{
    fn new() -> Counter{
        Counter {count: 0}
    }
}

impl Iterator for Counter{
    type Item = u32; // See more about assocaited types later.

    fn next(&mut self) -> Option<Self::Item>{ // next is the only method we need to implement.
        if self.count < 5{
            self.count += 1;
            Some(self.count)
        }else {
            None
        }
    }
}

#[test]
fn calling_next_directly(){
    let mut counter = Counter::new();

    assert_eq!(counter.next(), Some(1));
    assert_eq!(counter.next(), Some(2));
    assert_eq!(counter.next(), Some(3));
    assert_eq!(counter.next(), Some(4));
    assert_eq!(counter.next(), Some(5));
    assert_eq!(counter.next(), None);
}

fn main() {}
\end{lstlisting}

\paragraph*{Default implementations for other methods on our iterator}\begin{lstlisting}
    #[test]
fn using_other_iterator_trait_methods(){
    let sum: u32 = Counter::new()// Creating a new counter
        .zip(Counter::new().skip(1))
        .map(|(a,b)| a*b) // map takes a closure and calls for each item in the iterator.
        .filter(|x|x%3 == 0)// Filter to only items divisible by three
        .sum(); // take the sum
    assert_eq!(18,sum);
}
\end{lstlisting}
The zip method takes in two iterators and zips them up into one iterator containing pairs of values. 
The first iterator is the one in which the method is called on and the parameter. 
skip(n) is an adaptor method that creates a new iterator that skips the n elements.
        
\subsection{Using Iterators to refactor the CLI program we made}

Note in our CLI program we created an vector of strings called args using env::args.collect(), but env::args is an iterator.

In our implementation block for config we had to use the clone() method to get the query and filename since args is a reference of to a [String] so we can't take ownership. Since we have ownership of iteratros, let us use them to remove this clone operation. 

\paragraph*{Improved Config}\begin{lstlisting}
    impl Config{
    pub fn new(mut args: env::Args) -> Result<Config, &'static str>{
       args.next(); // Returns our first command line argument, we are discarding it since it is the path to our program which we don't care about.

       let query = match args.next(){ //query is taking ownership of it's string
        Some(arg) => arg, 
        None => return Err("Didn't get a query string"),
       };

       let filename = match args.next(){//filename is taking ownership of it's string
        Some(arg) => arg,
        None => return Err("Didn't get a filename"),
       };
        
        let case_sensitive = env::var("CASE_INSENSITIVE").is_err(); 

        Ok(Config {query, filename, case_sensitive}) //Ok is taking ownershiup of the strings.
    } 
\end{lstlisting}

\paragraph*{Improved search function with iterator adaptors}\begin{lstlisting}
    
pub fn search<'a>(query: &str, contents: &'a str) -> Vec<&'a str>{
    contents
        .lines()
        .filter(|line| line.contains(query)) // filter to lines that contains our query
        .collect() // Here rust knows what to collect into since it is specified as return type.
}
\end{lstlisting}

\newpage
\paragraph*{full lib.rs file}\begin{lstlisting}
use std::fs;
use std::error::Error;
use std::env;
pub fn run(config: Config) -> Result<(), Box<dyn Error>>{
    let contents = fs::read_to_string(config.filename)?;     
    let results = if config.case_sensitive{
        search(&config.query, &contents)
    }else{
        search_case_insensitive(&config.query, &contents)
    };
    for line in results{
            println!("{}", line);
    }
    Ok(())
}
pub struct Config{
    pub query: String,
    pub filename: String,
    pub case_sensitive: bool,
}
impl Config{
    pub fn new(mut args: env::Args) -> Result<Config, &'static str>{
       args.next();
       let query = match args.next(){
        Some(arg) => arg,
        None => return Err("Didn't get a query string"),
       };
       let filename = match args.next(){
        Some(arg) => arg,
        None => return Err("Didn't get a filename"),
       };
        let case_sensitive = env::var("CASE_INSENSITIVE").is_err(); 
        Ok(Config {query, filename, case_sensitive})
    } 
}
pub fn search<'a>(query: &str, contents: &'a str) -> Vec<&'a str>{
    contents
        .lines()
        .filter(|line| line.contains(query)) // filter to lines that contains our query
        .collect() // Here rust knows what to collect into since it is specified as return type.
}

pub fn search_case_insensitive<'a>(
    query: &str,
    contents: &'a str,
) -> Vec<&'a str>{
    let query = query.to_lowercase();
    let mut results = Vec::new();
    for line in contents.lines(){
        if line.to_lowercase().contains(&query){
            results.push(line);  
        }
    }
    results
}
// Tests here 
}
\end{lstlisting}

\paragraph*{full main.rs file}\begin{lstlisting}
use std::env;
use std::process;
use iterators::Config;
fn main() {
    let config= Config::new(env::args()).unwrap_or_else(|err|{
        eprintln!("Problem parsing arguments {}", err);
        process::exit(1);
    });
    println!("Searching for {}", config.query);
    println!("In file {}", config.filename);
    if let Err(e) = iterators::run(config){
        eprintln!("Application error: {}", e);
        process::exit(1);
    }
}
\end{lstlisting}

\subsection{Loops vs Iterators}

Is there a performance impact to using loops vs iterators? \textbf{NO}, using higher level abstractions like iterators over loops doesn't have an impact on performance. So using iterators and loops is equivalent.
In general people prefer to use iteratros since it is a higher level of abstraction and we get access to useful methods.

\section{Publishing a Crate}
\subsection{Release Profiles}

\begin{definition}
    \textbf{Release Profiles} allow you to configure how your code is compiled. There are two profile\begin{enumerate}
        \item \textbf{Dev} defined with good default for development.
        \item \textbf{Release} define with good defaults for release.
    \end{enumerate}

    If we run cargo build, it compiles with dev profile if we run cargo build --release it compiles with release profile. 
    We can customise the setting in the cargo.toml file.

    \begin{lstlisting}
[package]
name = "my_crate"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]


[profile.dev]
opt-level = 0

[profile.release]
opt-level = 3
\end{lstlisting}

Here opt-level tellls the level of optimization we want, $0$ being the least and $3$ being the most. We can modify the level as we want. The full list of setting is on cargo documentation.


\subsection{Uploading code to crates.io}
Before talking about how to upload our code to carates.io, we wiil show how to prepare our code.
\subsubsection{Preparing our code}
\paragraph*{Documentation Comments}

Documentation comments are useful when documenting public api so that others know how to use our code. Documentation code starts with three slashes and uses Markdown for formatting. Rust will turn our documentation into a html format that is easy to read.

\subparagraph*{Example of documentation comment}\begin{lstlisting}
/// Adds one to the number given.
///
/// # Examples
///
/// ```
/// let arg = 5;
/// let answer = my_crate::add_one(arg);
///
/// assert_eq!(6, answer);
/// ```
pub fn add_one(x: i32) -> i32 {
    x + 1
}
\end{lstlisting}

In first line we explain what the function does and then we have an example section that gives an example of how to use our function. Note Rust will run our assert statement as a test, if we run cargo test. This forces our documetation to be in-synced with the code.

In order to build the html documentation for our crate we write:\begin{lstlisting}
    cargo doc --open
\end{lstlisting}

\subparagraph*{Other commonly used section}\begin{enumerate}
    \item Panics: The scenarios in which the function being documented could panic.
    \item Errors: If the function returns a Result, describing the kinds of errors that might occur and what conditions might cause those errors.
    \item Safety: Explains why our function is unsafe and conditions when our function panics.
\end{enumerate}
\end{definition}

\subparagraph*{Documentating item containing the comment}

If we use //! we will instead of documenting the item follwing the comment it documents the item containg the comment in this example in lib.rs:\begin{lstlisting}    
//! My Crate
//! 
//! `my_crate` is a collection of utilities to make perfoming certain
//! calculations more convenient
\end{lstlisting}

So this is documenting our library crate.

\subsection{Exporting a public API}

We have an example where we create an Art module that let's us mix colours:\begin{lstlisting}
    //! # Art
//!
//! A library for modeling artistic concepts.

pub mod kinds {
    /// The primary colors according to the RYB color model.
    pub enum PrimaryColor {
        Red,
        Yellow,
        Blue,
    }

    /// The secondary colors according to the RYB color model.
    pub enum SecondaryColor {
        Orange,
        Green,
        Purple,
    }
}

pub mod utils {
    use crate::kinds::*;

    /// Combines two primary colors in equal amounts to create
    /// a secondary color.
    pub fn mix(c1: PrimaryColor, c2: PrimaryColor) -> SecondaryColor {
        // --snip--
        // ANCHOR_END: here
        SecondaryColor::Orange
        // ANCHOR: here
    }
}
\end{lstlisting}

Here is how we would access these functions in main.rs\begin{lstlisting}
use my_crate::kinds::PrimaryColor;
use my_crate::utils::mix;

fn main() {
    let red = PrimaryColor::Red;
    let yellow = PrimaryColor::Yellow;
    mix(red,yellow);
}
\end{lstlisting}
Let's say that we want users to have access of our enums and mix function at the top level without having to mention their modules.

\subparagraph*{Use the ``pub use'' keyword}\begin{lstlisting}
pub use self::kinds::PrimaryColor;
pub use self::kinds::SecondaryColor;
pub use self::utils::mix;
\end{lstlisting}

If we go back to main.rs we can import our items from top level of our library:\begin{lstlisting}
use my_crate::PrimaryColor;
use my_crate::mix;
\end{lstlisting}

pub use statement allow us to make the public api different from the internal structure of our program.

\subsection{Publishing to crate.io}
Currently we must have a github account to log into crate.io, we need to go to the account setting to get an API token (which we should not share with anyone) and run \begin{lstlisting}
    cargo login tokenabcsdfefefmakcn
\end{lstlisting} 

Which will log us in, after we are successfuly logged in. Now we can publish but before we do that we must double-check the meta data. When we are developping uniquely our name does not matter but when publishing to cargo.io our name must be unique. 
So we must go to crates.io and check that our desired name isn't taken. In this case our name is ``my\_crate''. We also need a description and a licence.


\textbf{Publishing to crates.io is permanant!} If we want to upload a new version we can update the version number in cargo.toml using the sematic versioning rules. While we can't delete or modify our crates on cargo.io we can stop certain version from being used with the \begin{lstlisting}
    cargo yank --vers *version_number*
\end{lstlisting}

So for anyone with this version in their cargo.lock file they can keep using this version. But those downloading our library for the first time won't be allowed to download this version.

If we want to undo our yank just do:\begin{lstlisting}
    cargo yank --vers *version_number* --undo
\end{lstlisting}

\section{Cargo Workspace}

\begin{definition}
    \textbf{Cargo Workspaces} help us manage multiple related packages that are developped in tandem. They share common dependencies resolution by having one Cargo.lock file, and they share one output directory and various settings like profiels.
\end{definition}

\begin{definition}
    Packages in our workspace are called \textbf{Workspace members}
\end{definition}

\paragraph*{Setting up workspace}\begin{lstlisting}
    [workspace]

    members =[
        "adder",
        "add-one",
    ]\end{lstlisting}

Note the Cargo.lock and target directory are made at the root of our workspace. If we want our adder directory to use our add-one file we need to put it in the dependencies of the adder Cargo.toml file:
\paragraph*{In add/adder/Cargo.toml}\begin{lstlisting}
[dependencies]
add-one = {path = "../add-one"}
\end{lstlisting}

And in main.rs we write:

\paragraph*{In add/adder/src/main.rs}\begin{lstlisting}
use add_one;

fn main() {
    let num = 10;
    println!(
        "Hello, world! {} plus one is {}!",
        num,
        add_one::add_one(num)
    );
}
\end{lstlisting}
In order to run our adder package we write \begin{lstlisting}
    cargo run -p adder
\end{lstlisting}


\subsection{External dependencies}

If we add a dependency in adder and add-one package they will resolve to the same version.

So we can add in rand as a dependency in add-one and when we do cargo build it will be added to the Cargo.lock file. Even though rand is a dependency of our add-one package, it doesn't mean we can use rand in every package.

If we try to bring rand into the scope of main.rs in adder folder we get an error, we must add rand in dependencies of adder Cargo.toml file.

\subsection{Testing}

\paragraph*{In /add-one/src/lib.rs:}\begin{lstlisting}
    use rand;

pub fn add_one(x:i32)->i32 {
    x+1
}

#[cfg(test)]
mod tests{
    use super::*;

    #[test]
    fn it_works(){
        assert_eq!(3,add_one(2));
    }
}
\end{lstlisting}

If we want to run tests just for add-one write \begin{lstlisting}
    cargo test -p add-one
\end{lstlisting}

\subsection{Homework}
Add another library add-two, which has a another function similar to add-one but adds two.

\subsection{Publishing}

If we want to publish a package withing workspace we must publish them individually. So cd in each directories and run cargo publish in each directory.

\section{Installing Binaries from crates.io with cargo install}
This is a convenient way for Rust developers to use tools built by other rust developers and published to crates.IoResult

\begin{remark}
    We can only install packages with binary targets. We need something we can execute.
\end{remark}

All binaries installed using cargo install are installed in the installation root's \textit{bin} directory.

\begin{example}\textbf{Installing ripgrep}
    For example we can install Rust's version of grep ripgrep like this:\begin{lstlisting}
        cargo install ripgrep 
    \end{lstlisting}
    The penultimate line of the output tells us where our package was installed and the last line tells us the name of of our executable. 
\end{example}
One cool thing with these binaries is that we can use them to extend cargo with custom commands. If we have a binary in our path prefixed by cargo, i.e. cargo-something. We can run this as a subcommand of cargo by typing\begin{lstlisting}
    cargo something
\end{lstlisting}

\section{Box smart Pointer}
\begin{definition}
    A \textbf{pointer} is a general concept for a variable that stores a memory adresse that referes or ``points'' to some data in memory. The most common type of pointer in Rust is a \textbf{reference} they borrow the values they point to, so they don't take ownership.
    References don't have any special capabilities so they don't have any overhead. Unlike \textbf{Smart Pointers} which is a data structure that acts with a structure with metadata and extra capabilities tacked on. In many cases Smart Pointers own the data they point to. Example of smart pointers are \textit{String} and \textit{Vectors}.
    Smart pointers are implemented using structs with the deref and drop trait. The \textbf{deref} trait lets instances of smart pointer struct to be treated as a reference. The \textbf{drop} trait allows you to customise the code that is run when an instance of our smart pointer goes out of scope. 
\end{definition}
We will only talk about the most common smart pointers in Rust.

\subsection{Box}
\begin{definition}
    \textbf{Box} is a smart pointer that allows you to allocate values on the heap.
\end{definition}

\paragraph*{Example}\begin{lstlisting}
    fn main() {
    let b=Box::new(5); // Storing 5 on the heap and on the stack we are storing memory adress to value of 5 on the heap.
    println!("b = {}", b);
}
\end{lstlisting}
When our Box goes out of scope it will be de-allocated, the box smart pointer on the stack will be de-allocated but also the data on the heap will be de-allocated.


Box's don't have any overhead except storing the data on the heap, they also don't have many other capabilities. 
\paragraph*{Typical uses of Box}
\begin{itemize}
    \item When we have a type whose exact size can't be known at compile time but what to use value in context that needs to know exact size
    \item When we have large amount of data and what to transfer ownership but not copy the data.
    \item When we own a value and only care that value implements a specific trait rather then it being a specific type. This is known as a \textbf{Trait object}.
\end{itemize}
Now we will look at a practical example of when we want to use the Box pointer.

\subsubsection{Box pointer and List enum}

\begin{definition}
    The \textbf{Cons list} is a data structure that comes from Lisp. Where each element in the list holds the value of the list and points to the next value until we reach the end of the list and point to Nil. 
\end{definition}


\paragraph*{List enum}\begin{lstlisting}
    enum List{ //Error recursive type has infinite size
    Cons(i32, List),
    Nil,
} 
\end{lstlisting}
Rust needs to know how much space this will take up at compile time but Rust doesn't know in this case, since our list can be ``arbitrarily'' large. This is a problem the Cons list shares with all other recursive data types.


To understand how to fix this with the Box pointer, we must first understand how computes the size of non-recursive enums.

\paragraph*{non-recursive enum}\begin{lstlisting}
    enum Message{
    Quit,
    Move{x:i32, y:i32},
    Write(String),
    ChangeColor(i32, i32, i32),
}
\end{lstlisting}
Rust will figure out the size needed to store an instance of Message, it will go through each variant and see at how much space each variant needs. Rust will figure out which variant uses the most amount of space this is the most space Message will take up (since we can only use one variant at time per instance).

But now for our list Enum we notice that the Cons variant stores a tuple type consisiing of an integer and a list enum, so rust must know how much space the list enum takes to know how much spac ethe list enum takes! 

How do we fix this?

\paragraph*{Fixing with the Box Smart Pointer}\begin{lstlisting}
    enum List{
    Cons(i32, Box<List>),
    Nil,
}
\end{lstlisting}
Why did this fix our error? Well if we look at each variant to see how much space List takes up we see that ``Nil'' takes no space and ``Cons'' stores an integer and a Box Smart Pointer, which is a fixed size pointer, while it points to some arbitrarily amount of data on the heap on the stack it is of fixed size. 


\paragraph*{Implementation}\begin{lstlisting}
    enum List{
    Cons(i32, Box<List>),
    Nil,
}

use List::{Cons,Nil};

fn main() {
    let list = Cons(1,Box::new(Cons(2, Box::new(Cons(3, Box::new(Nil))))));
}
\end{lstlisting} 
Our code compiles without errors.

\subsection{Deref Triat}
\subsubsection{Dereference operator `*'}

\begin{definition}
    For references the \textbf{deference operator} follows memory address stoered in reference to the actual value.
\end{definition}

\begin{lstlisting}
    fn main (){
    let x = 5;
    let y = &x;

    assert_eq!(5,x); //True
    assert_eq!(5,*y); //True 
    assert_eq!(5,y); //Error can't compare `{integer}` with `&{integer}`
}
\end{lstlisting}

We can modify this example to use smart pointers, specifically the smart pointer Box.
\paragraph*{Now with the Box Smart Pointer}\begin{lstlisting}
    fn main (){
    let x = 5;
    let y = Box::new(x);

    assert_eq!(5,x);
    assert_eq!(5,*y); // Derefence operator works the same since Box implements the deref trait
}
\end{lstlisting}

Let us build our own Box pointer to understand how the deref trait works in more detail.

\paragraph*{MyBox}\begin{lstlisting}
    use std::ops::Deref; // Bring Deref trait into scope

struct MyBox<T>(T);

impl <T> MyBox<T>{
    fn new(x:T) -> MyBox<T>{
        MyBox(x) // Note unlike MyBox, Box doesn't store data on the heap.
    }
}

impl<T> Deref for MyBox<T>{
    type Target = T; // We will talk about this later

    fn deref(&self) -> &T{
        &self.0 //Return a reference to item stored in tuple struct.
    }
}

fn main (){
    let x = 5;
    let y = MyBox::new(x);

    assert_eq!(5,x);
    assert_eq!(5,*y);
}
\end{lstlisting}
The deref trait allows the Rust compiler to take any value that implememnts deref call the deref method to get a reference which the compiler knows how to dereference. 

More clearly at the last line of our above example here is what the compiler calls:\begin{lstlisting}
    assert_eq!(5,*(y.deref()));
\end{lstlisting}

This allows us to treatregular reference and types that implements the deref trait the same.

Why doesn't deref return the value itself? The ownership system! If Rust returns the value directly, it will move ownership of the value outside of our smart pointer.

\subsubsection{Deref Coercion}

\begin{definition}
    \textbf{Deref Coercion} is a convenience feature in Rust that happens automatically for types that implement the deref trait, deref coercion will convert a reference of one type to a reference of a different type.      
\end{definition}
\paragraph*{Example}\begin{lstlisting}
// MyBox implementation here
fn main (){
    let m = MyBox::new(String::from("Rust"));
    hello(&m); 
}

fn hello(name: &str){
    println!("Hello, {}!", name);
}
\end{lstlisting}

This code works even if \&m is a reference to my box.

\paragraph*{Explanation}\begin{lstlisting}
    // &MyBox<String> ->(deref) &String ->(deref) &str
\end{lstlisting}
Rust sees that the type being passed to hello is different than the type expected by the funciton, and automatically performs these chained deref calls to get the correct type.

If Rust didn't have automatic deref coercion we would have to write our code like this:\begin{lstlisting}
    hello(&(*m)[...]);
\end{lstlisting}

\begin{definition}\textbf{Deref Mut}:

Similar to how we use the deref trait to override deref operator for immutatable references, we can use the DerefMut for mutable references.
\end{definition}

Rust does deref coercion in the follwing cases:\begin{itemize}
    \item Immutable ref to immutable ref
    \item mutable ref to mutable ref
    \item mutable ref to immutable ref
\end{itemize}

Rust cannot perform deref coercion when going from immutable ref to mutable ref due to the borrowing rules, \textbf{we can only have one mutable reference to a specific piece of data in a specific scope}.
\subsection{Drop Trait}
\begin{definition}
    The \textbf{drop trait} can be implemented on any type and it tells you what to do when the value goes out of scope. It is mostly used with smart pointers, for example in the box pointer it tells the compiler to deallocate the data stored on the heap.
\end{definition}

\paragraph*{Example}\begin{lstlisting}
    struct CustomSmartPointer{
    data:String,
}

impl Drop for CustomSmartPointer{ // Drop trait requires that we implement the drop method.
    fn drop(&mut self) {
        println!("Dropping CustomeSmartPointer with data `{}`!", self.data);
    }
}


fn main() {
    let c = CustomSmartPointer{
        data: String::from("my stuff"),
    };
    let d = CustomSmartPointer{
        data: String::from("other stuff"),
    };
 println!("CustomSmartPointers created.");
}
\end{lstlisting}
\paragraph*{Output}\begin{lstlisting}
CustomSmartPointers created.
Dropping CustomeSmartPointer with data `other stuff`!
Dropping CustomeSmartPointer with data `my stuff`!
\end{lstlisting}

What happens if we want to customise the cleanup behaviour? Like if we want to clean up early, for example if we are managing locks, we might want to drop the smart pointer to release the lock so that other code can use the data.

\paragraph*{Using c.drop() directly}\begin{lstlisting}
fn main() {
    let c = CustomSmartPointer{
        data: String::from("my stuff"),
    };
    let d = CustomSmartPointer{
        data: String::from("other stuff"),
    };
    println!("CustomSmartPointers created.");
    c.drop(); // Error explicit destructor calls not allowed.
    println!("Dropped before end of main"); 
}    
\end{lstlisting}
We are not allowed to use the drop method manually since when our variable goes out of scope, Rust will call the drop method again which may lead to a double free.

To manually cleanup the value early, we call the drop function:
\newpage
\paragraph*{drop(c)}\begin{lstlisting}
    fn main() {
    let c = CustomSmartPointer{
        data: String::from("my stuff"),
    };
    let d = CustomSmartPointer{
        data: String::from("other stuff"),
    };
    println!("CustomSmartPointers created.");
    drop(c);
    println!("Dropped before end of main"); 
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
CustomSmartPointers created.
Dropping CustomeSmartPointer with data `my stuff`!
Dropped before end of main
Dropping CustomeSmartPointer with data `other stuff`!
\end{lstlisting}
\subsection{Reference Counting}
\begin{definition}
A \textbf{reference counting smart pointer} allows us to share ownership. While most of the time ownership is clear, there are cases where a single value has mutliple owners, for example in a graph a node is owned by all the edges pointing to it, and should not be cleaned up unless no edges point to it. So we use a reference counting smart pointer which keep track of the number of references to a value and when there are no more reference the value is cleaned up.
An analogy is when watching tv, we only turn off the tv when everyone in the room has left, if we turn it off while there are still people in the room, there will be panic.        
\end{definition}

The referece counting smart pointer is used when we have a value on the heap and multiple parts of our program read that value and we don't know which part of our program is going to use our value last at compile time.
\begin{remark}
The reference counting smart pointer we will see is only used in single threaded programs, we will later see how to use reference counting in multi-threaded programs.
\end{remark} 

\paragraph*{Trying to use Box pointer}\begin{lstlisting}
    enum List{
    Cons(i32, Box<List>),
    Nil,
}

use crate::List::{Cons,Nil};

fn main() {
// b and c both point to a
    let a = Cons(5, Box::new(Cons(10, Box::new(Nil))));
    let b = Cons(3,Box::new(a)); // Value of a moved here
    let c = Cons(4,Box::new(a)); // Error, value used after move
}
\end{lstlisting}
\paragraph*{Using reference counting}\begin{lstlisting}
    use std::rc::Rc;

enum List{
    Cons(i32, Rc<List>),
    Nil,
}

use crate::List::{Cons,Nil};

fn main() {
// b and c both point to a
    let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil)))));
    let b = Cons(3,Rc::clone(&a)); 
    let c = Cons(4,Rc::clone(&a));
}
\end{lstlisting}

Here we want both b and c to point to the Cons list a. We can't pass in a reference to a in b since we expect an ownede type, so we will have mismatched types. And we can't pass in a directly since then we will move ownership of a into b.
So the answer is to use the clone method, here the clone method doens't deep copy the value it only increasess the reference count.

\paragraph*{In more details}\begin{lstlisting}
fn main() {
    let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil)))));
    println!("count after creating a = {}", Rc::strong_count(&a)); // 1
    let b = Cons(3,Rc::clone(&a)); 
    println!("count after creating b = {}", Rc::strong_count(&a)); // 2
    {
        let c = Cons(4,Rc::clone(&a));
        println!("count after creating c = {}", Rc::strong_count(&a)); // 3
    }
    println!("count after c leaves scope = {}", Rc::strong_count(&a)); // 2
}
\end{lstlisting}
\begin{remark}
    The reference counting smart pointer, let's multiple parts of our program to read the same data but not to modify it. If we allowed multiple mutable references we would be violating the borrowing rules. 
\end{remark}

\subsection{Interior mutability}
\begin{definition}
    \textbf{Interior mutatbility} is a design pattern that let's us to mutate data even when there are immutable reference to that data. To do so it uses unsafe code inside a data structure to bypass the borrowing rules. We will learn more about unsafe code later.
\end{definition}

Even though the borrowing rules are not enforced at compile time they can still be enforced at run time.

\subsubsection{RefCell Smart pointer}
\begin{definition}
    The \textbf{RefCell} Smart pointer represents single ownership over the data it holds, like the Box smart pointer. But the Box enforces borrowing at compile time while RefCell enforces borrowing rules at run time.
\end{definition}

The advantages of checking the borrowing rules at run time is that certain memory safe scenarios are allowed which would be dissallowed at compile time. The RefCell smart pointer is useful when you are sure that you are following the borrowing rules but the compile can't tell that. 

\begin{remark}
    We can only use RefCell in single threaded programs. We will look at what to do for multi-threaded programs later.
\end{remark}

Mutating a value inside an immutable value is called the interior mutability pattern.

\begin{lstlisting}
    
fn main() {
    let a  = 5;
    let b = &mut a; //Error: a is immutable so cannot borrow as mutable

    let mut c = 10;
    let d = &c;
    *d = 20; //Error: d is an immutable reference so the data it referes to cannot be written
}
\end{lstlisting}

We can solve this with some inderection. We can use a data structure that stores some value, where the value in the data structure is mutable but when we get a reference to the data structure the reference is immutable. So code outside the data structure can't mutatate the value, but we can call methods on the data structure to mutate the data.

This is what the RefCell smart pointer does with one caviate, instead of calling methods to mutate the data we call methods to get a mutable or immutable reference of the data.

\subsubsection{Use case for interior mutability pattern}

\paragraph*{Example}\begin{lstlisting}
    pub trait Messenger{
    fn send(&self, msg: &str);
}

pub struct LimitTracker<'a, T:Messenger>{ // add liftime annotation since we are borrowing T
    messenger: &'a T,
    value: usize, // pointer-sized unsigned integer type.
    max: usize,
}

impl<'a, T> LimitTracker<'a, T>
where
    T:Messenger,
{
    pub fn new(messenger: &T, max:usize) -> LimitTracker<T>{
        LimitTracker{
            messenger,
            value:0,
            max,
        }
    }
}

pub fn set_value(&mut self, value: usize) {
    self.value = value;

    let percentage_of_max = self.value as f64 / self.max as f64;

    if percentage_of_max >= 1.0 {
        self.messenger.send("Error: You are over your quota!");
    } else if percentage_of_max >= 0.9 {
        self.messenger
            .send("Urgent warning: You've used up over 90% of your quota!");
    } else if percentage_of_max >= 0.75 {
        self.messenger
            .send("Warning: You've used up over 75% of your quota!");
    }
}
\end{lstlisting}
This is a library that tracks a value against maximal value and sends message depending on ratio between value with maximal.

Let us implement our tests:

\paragraph*{Testing}\begin{lstlisting}
    #[cfg(test)]
mod tests {
    use super::*;

    struct MockMessenger {
        sent_messages: Vec<String>, //vector of sent message
    }

    impl MockMessenger {
        fn new() -> MockMessenger {
            MockMessenger {
                sent_messages: vec![],
            }
        }
    }

    impl Messenger for MockMessenger {// pushes message to the vector
        fn send(&self, message: &str) {
            self.sent_messages.push(String::from(message));  //Error cannot borrow `self.sent_messages` as mutable, as it is behind a `&` reference 
        }
    }

    #[test]
    fn it_sends_an_over_75_percent_warning_message() {
        let mock_messenger = MockMessenger::new();
        let mut limit_tracker = LimitTracker::new(&mock_messenger, 100);

        limit_tracker.set_value(80);

        assert_eq!(mock_messenger.sent_messages.len(), 1); //We should have one message
    }
}
\end{lstlisting}

We need an mutable reference but that would break the function signature of send defined in our messenger trait. In this situation we can use the RefCell.
\newpage
\paragraph*{Once again with RefCell}\begin{lstlisting}
    #[cfg(test)]
mod tests {
    use super::*;
    use std::cell::RefCell;

    struct MockMessenger {
        sent_messages: RefCell<Vec<String>>,
    }

    impl MockMessenger {
        fn new() -> MockMessenger {
            MockMessenger {
                sent_messages: RefCell::new(vec![]),
            }
        }
    }

    impl Messenger for MockMessenger {
        fn send(&self, message: &str) {
            self.sent_messages.borrow_mut().push(String::from(message)); 
        }
    }

    #[test]
    fn it_sends_an_over_75_percent_warning_message() {
        let mock_messenger = MockMessenger::new();
        let mut limit_tracker = LimitTracker::new(&mock_messenger, 100);

        limit_tracker.set_value(80);

        assert_eq!(mock_messenger.sent_messages.borrow().len(), 1); 
    }
}// All tests pass
\end{lstlisting}


Now recall that RefCell checks the borrowing rules at runtime, so what happens when we have two mutable references at the same time?

\paragraph*{Two borrows}\begin{lstlisting}
impl Messenger for MockMessenger {
    fn send(&self, message: &str) {
        let mut one_borrow = self.sent_messages.borrow_mut();
        let mut two_borrow = self.sent_messages.borrow_mut();
            
        one_borrow.push(String::from(message));
        two_borrow.push(String::from(message));
    }
} // Tests fails: thread 'tests::it_sends_an_over_75_percent_warning_message' panicked at 'already borrowed: BorrowMutError', src/lib.rs:60:53
\end{lstlisting}

So the interior mutability pattern gives us flexability but we must still follow the borrowing rules.

\subsubsection{Combining Rc with RefCell to get multiple owners of mutable data}
\paragraph*{Expanding our list code}\begin{lstlisting}
#[derive(Debug)]

enum List{
    Cons(Rc<RefCell<i32>>, Rc<List>),
    Nil,
}

use crate::List::{Cons, Nil};
use std::cell::RefCell;
use std::rc::Rc;

fn main(){
    let value = Rc::new(RefCell::new(5));

    let a = Rc::new(Cons(Rc::clone(&value), Rc::new(Nil)));

    let b = Cons(Rc::new(RefCell::new(3)), Rc::clone(&a));
    let c = Cons(Rc::new(RefCell::new(4)), Rc::clone(&a));

    *value.borrow_mut() += 10; // Automatic dereferencing feature.

    println!("a after = {:?}", a);
    println!("b after = {:?}", b);
    println!("c after = {:?}", c);
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
a after = Cons(RefCell { value: 15 }, Nil)
b after = Cons(RefCell { value: 3 }, Cons(RefCell { value: 15 }, Nil))
c after = Cons(RefCell { value: 4 }, Cons(RefCell { value: 15 }, Nil))
\end{lstlisting}

\subsubsection{Recap of the smart pointers we have seen}
\begin{itemize}
    \item Rc: enables multiple ownership of the same data; allows only immutable borrows checked at compile time.
    \item Box: Allow single ownership to piece of data; allows immutable or mutable borrows checked at compile time.
    \item RefCell: Allows single ownership to piece of data; allows immutable or mutable borrows checked at runtime. (So we mutate value inseide RefCell<T> even when RefCell<T> is immutable)
\end{itemize}

\subsection{Reference Cycles}

Rust is known for being a memory safe language, so it provides certain guarentees like you can't have data races. But it doesn't guarentee that we will not have memory leaks. We can create a memory leak with the Rc and RefCell smart pointers, with these two smart pointers we can create references where items reference eachother in a cylce. Which will create a memory leak.

\paragraph*{Rxample of memory leak}\begin{lstlisting}
    use crate::List::{Cons,Nil};
use std::cell::RefCell;
use std::rc::Rc;

#[derive(Debug)]

enum List{
    Cons(i32, RefCell<Rc<List>>),
    Nil,
}

impl List{
    fn tail(&self) -> Option<&RefCell<Rc<List>>>{
        match self{
            Cons(_, item) => Some(item),
            Nil => None,
        }
    }
}

fn main() {
    let a = Rc::new(Cons(5, RefCell::new(Rc::new(Nil))));

    println!("a initial rc count = {}", Rc::strong_count(&a));  // 1
    println!("a next item ={:?}", a.tail());

    let b = Rc::new(Cons(10,RefCell::new(Rc::clone(&a))));

    println!("a rc count after b creation = {}", Rc::strong_count(&a)); // 2
    println!("b initial rc count = {}", Rc::strong_count(&b)); // 1
    println!("b next item = {:?}", b.tail()); // List a


    if let Some(link) = a.tail(){ // udr if let since we only care about Some 
        *link.borrow_mut() = Rc::clone(&b); // We get mutable ref to the data and use dereference operator to change the data into list b.
    }
    println!("b rc count after changing a = {}", Rc::strong_count(&b)); // 2
    println!("a rc count after changing a = {}", Rc::strong_count(&a)); // 2
}
//This line proves we have a cycle, it will overflow the stack
println!("a next item = {:?}", a.tail()); 
\end{lstlisting}
We have created a cycle since list a reference list b and list b references list a. More clearly the tail of list a points to list b but the tail of list b points to list a, so when we try to print it on the last line, to print list a it will print list b, but to print list b it will print list a, etc\dots

These circular dependencies also cause a memory leak. Indeed at the end of main a and b will get cleaned up, when b get's cleaned up the memory on the stack is not cleaned up since it is still reference in list a. Then a gets cleaned up but the memory on the heap doesn't get cleaned up since it is reference in the tail of list b.

So we have data on the heap but we don't have any stack variables pointing on this list.

\subsubsection{Tree structure without referece cycles}
\begin{definition}
    The \textbf{Weak} smart pointer is a version of the Rc smart pointer that holds a non-owning reference.
\end{definition}

\begin{lstlisting}
    use std::cell::RefCell;
use std::rc::{Rc, Weak};

#[derive(Debug)]

struct Node{
    value: i32,
    parent: RefCell<Weak<Node>>,//Can't use Rc since it will cause a reference cycle.
    children: RefCell<Vec<Rc<Node>>>,
}

fn main() {
    let leaf = Rc::new(Node{
        value: 3,
        parent: RefCell::new(Weak::new()),
        children: RefCell::new(vec![]),
    });

    println!("leaf parent = {:?}", leaf.parent.borrow().upgrade()); //upgrade attempts to turn Weak into Rc, returns None if value was dropped otherwise it returns Some with Rc

    let branch = Rc::new(Node{
        value: 5,
        parent: RefCell::new(Weak::new()),
        children: RefCell::new(vec![Rc::clone(&leaf)]),
    });

    *leaf.parent.borrow_mut() = Rc::downgrade(&branch); // downgrade turns Rc smart pointer into weak smart pointer. 

    println!("leaf parent = {:?}", leaf.parent.borrow().upgrade()); 
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
leaf parent = None
leaf parent = Some(Node { value: 5, parent: RefCell { value: (Weak) }, children: RefCell { value: [Node { value: 3, parent: RefCell { value: (Weak) }, children: RefCell { value: [] } }] } })
\end{lstlisting}

\paragraph*{Strong and weak count}\begin{lstlisting}
fn main() {
    let leaf = Rc::new(Node{
        value: 3,
        parent: RefCell::new(Weak::new()),
        children: RefCell::new(vec![]),
    });

    println!(
        "leaf strong = {}, weak = {}",
        Rc::strong_count(&leaf), // 1
        Rc::weak_count(&leaf), // 0
    );
    
    {
        let branch = Rc::new(Node{
            value: 5,
            parent: RefCell::new(Weak::new()),
            children: RefCell::new(vec![Rc::clone(&leaf)]),
        });

        *leaf.parent.borrow_mut() = Rc::downgrade(&branch); // downgrade turns Rc smart pointer into weak smart pointer. 

        println!(
            "branch strong = {}, weak = {}",
            Rc::strong_count(&branch), // 1
            Rc::weak_count(&branch), // 1, since leaf has a weak reference to branch
        );

        println!(
            "leaf strong = {}, weak = {}",
            Rc::strong_count(&leaf), // 2, since leaf is a child of branch
            Rc::weak_count(&leaf), // 0
        );

    }
    println!("leaf parent = {:?}", leaf.parent.borrow().upgrade()); //None since branch is dropped 
    println!(
        "leaf strong = {}, weak = {}",
        Rc::strong_count(&leaf), // 1
        Rc::weak_count(&leaf), // 0
    );
}
\end{lstlisting}
\paragraph*{Output}\begin{lstlisting}
leaf strong = 1, weak = 0
branch strong = 1, weak = 1
leaf strong = 2, weak = 0
leaf parent = None
leaf strong = 1, weak = 0
\end{lstlisting}


\section{Fearless Concurrency}
\begin{definition}
    \textbf{Concurrent} programming is when different part of program execute concurrently and \textbf{parallel programming} is when different part of the code execute at the same time. In these notes when we say concurrency, we mean both concurrency and parallel. 
\end{definition}

\begin{definition}
    Within a program we can have multiple parts that run at the same time, the features that run these parts of the program are called \textbf{threads}.
\end{definition}

\paragraph*{Challenges}:\begin{itemize}
    \item \textbf{Race conditions}, threads are accessing data/resources in inconsistent order
    \item \textbf{Dead locks}, if two threads both waiting for a resource that another thread has.
    \item \textbf{Hard to reproduce and fix bugs}, since execution order is non-determinastic. 
\end{itemize}

\paragraph*{Main kinds of threads}\begin{itemize}
    \item 1 to 1 threads, aka OS threads, etc..; when we create a thread in our program it maps to our OS thread. So there is a 1 to 1 mapping between the two.
    \item Green threads, aka user threads, program threads, etc..; special implememntation of threads provided by the programming language. They don't have a 1 to 1 mapping to OS threads.
\end{itemize}
Rust aims to have an extremly small runtime, so it must sacrifice features. Since Green threads will require a larger language runtime, Rust only includes 1 to 1 threads  in the standard library. If we want to use green threads we must use crates.

\subsection{Implementing threads}

\paragraph*{Spawning a thread}\begin{lstlisting}
    use std::{thread, time::Duration};


fn main() {
    thread::spawn(||{
        for i in 1..10{
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1)); // Pause execution of thread for a milisecond.
        }
    });

    for i in 1..5{
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
hi number 1 from the main thread!
hi number 1 from the spawned thread!
hi number 2 from the spawned thread!
hi number 2 from the main thread!
hi number 3 from the spawned thread!
hi number 3 from the main thread!
hi number 4 from the spawned thread!
hi number 4 from the main thread!
hi number 5 from the spawned thread!
\end{lstlisting}
Note the main thread finished printing all of it's numbers, but the spawned thread didn't. This is because when the main thread ends the spawned thread stops.

How do we fix the code to make sure that the spawned thread finished execution.

\paragraph*{Code}\begin{lstlisting}
    use std::{thread, time::Duration};


fn main() {
    let handle = thread::spawn(||{
        for i in 1..10{
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1)); // Pause execution of thread for a milisecond.
        }
    });

    for i in 1..5{
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }

    handle.join().unwrap();
}
\end{lstlisting}
Calling join() blocks the thread currently running(main thread in this case) until the  thread associated with join (i.e. spawned thread) terminates. Blocking a thread prevents it from doing any further work or exiting. 

\paragraph*{Output}\begin{lstlisting}
hi number 1 from the main thread!
hi number 1 from the spawned thread!
hi number 2 from the main thread!
hi number 2 from the spawned thread!
hi number 3 from the main thread!
hi number 3 from the spawned thread!
hi number 4 from the main thread!
hi number 4 from the spawned thread!
hi number 5 from the spawned thread!
hi number 6 from the spawned thread!
hi number 7 from the spawned thread!
hi number 8 from the spawned thread!
hi number 9 from the spawned thread!
\end{lstlisting}

If we move our handle.join() right after our spawn thread is created, the main thread will wait until the spawn thread is finished executing.
\paragraph*{Output if we move handle}\begin{lstlisting}
hi number 1 from the spawned thread!
hi number 2 from the spawned thread!
hi number 3 from the spawned thread!
hi number 4 from the spawned thread!
hi number 5 from the spawned thread!
hi number 6 from the spawned thread!
hi number 7 from the spawned thread!
hi number 8 from the spawned thread!
hi number 9 from the spawned thread!
hi number 1 from the main thread!
hi number 2 from the main thread!
hi number 3 from the main thread!
hi number 4 from the main thread!
\end{lstlisting}

So where the join method is called can affect if our threads run at the same time.

\subsection{Move closures}

Up until this point, the thread did not depend on any variable outside of our thread.

\paragraph*{Error}\begin{lstlisting}
    fn main() {
    let v = vec![1,2,3];
    
    let handle = thread::spawn(||{ //Compile time error: the closure may outlive the current function, but borrows v which is owned by current function.
        println!("Here's a vector: {:?}", v);
    });

    drop(v); //oh no!

    handle.join().unwrap();
}
\end{lstlisting}

The rust compiler doesn't know if v is always a valid reference. If our code was allowed to run, we could enter the main thread drop the value v, then switch back to the spawned thread, at which point v is invalid.

So Rust doesn't allow us to take a reference to $v$, our thread must take ownership with the move keyword.

\paragraph*{move keyword to force closure to take ownership}\begin{lstlisting}
    fn main() {
    let v = vec![1,2,3];
    
    let handle = thread::spawn(move ||{ //closure takes ownership of v
        println!("Here's a vector: {:?}", v);
    });

    handle.join().unwrap();
}
\end{lstlisting}
\subsection{Using data to pass messages between threads}
One popular approach to insure safe concurrency is message passing. Where we have threads(actors) passing messagees to eachother which contains data. One tool rusts provides in the std library to pass message is a channel. Like a channel of water, we can pass something on the stream it will travel downstream to the end of the water way.

A channel in programming has two halves the transceiver (upstream) and the reciever (downstream). The channel is closed if the reciever or  

\paragraph*{Implementing a channel}\begin{lstlisting}
    use std::sync::mpsc; // mpsc = multi-producer, single consumer.
use std::thread;

fn main() {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move ||{ // We need to use move keyword to move tx into the closure, in order to pass msg into tx.
        let msg = String::from("hi");
        tx.send(msg).unwrap(); // send() returns a result type, if the recieving end is dropped then send() returns an error, in real life we want to handle this more gracefully
    });

    let recieved = rx.recv().unwrap(); // recv() blocks main thread execution while it waits for a value to be sent by channel. Returns a result type; if the channel closes get error.
    
    //let recieved = rx.try_recv().unwrap(); try_recv(), doesn't block main thread execution, instead returns result immediately.
    
    println!("Got: {}", recieved);
}
\end{lstlisting}

\subsubsection{Ownership rules}
Ownership rules help us, prevent errors in our concurrent code. When we call send and pass in our value, send takes ownership of our value. So we can't modify or drop our value after it is being passed to another thread.

\subsubsection{Passing multiple messages}
We will pass multiple messages in order to prove that our code is running concurrently
\begin{lstlisting}
    use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move ||{ 
        let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
        ];

        for val in vals{
            tx.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    for recieved in rx{ 
        println!("Got: {}", recieved);
    }
}
\end{lstlisting}

\paragraph*{Output}\begin{lstlisting}
Got: hi
Got: from
Got: the
Got: thread
\end{lstlisting}

\subsubsection{Creating multiple producers}

\begin{lstlisting}
fn main() {
    let (tx, rx) = mpsc::channel();

    let tx2 = tx.clone();

    thread::spawn(move ||{ 
        let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
        ];

        for val in vals{
            tx.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    thread::spawn(move ||{ 
        let vals = vec![
            String::from("more"),
            String::from("messages"),
            String::from("for"),
            String::from("you"),
        ];

        for val in vals{
            tx2.send(val).unwrap(); //Can't use tx since already moved in previous thread.
            thread::sleep(Duration::from_secs(1));
        }
    });

    for recieved in rx{ 
        println!("Got: {}", recieved);
    }
}
\end{lstlisting}

Note our program is non-determinastic, when we run it may recive the messages in a different order

\paragraph*{Output 1}\begin{lstlisting}
Got: hi
Got: more
Got: from
Got: messages
Got: for
Got: the
Got: you
Got: thread
\end{lstlisting}

\paragraph*{Output 2}\begin{lstlisting}
Got: hi
Got: more
Got: messages
Got: from
Got: for
Got: the
Got: you
Got: thread
\end{lstlisting}
\subsection{Transfering data with shared state}
Unlike with the channel where we are passing ownership of a piece of data form one thread to another, with shared state concurrency we have some piece of data in memory that multiple threads can read and write to.

\subsubsection{Mutex}
\begin{definition}
    \textbf{Mutex} means mutual exclusion, this means that only one thread can access a piece of data at any time. We achieve this with a locking system. The lock is a data structure that keeps track on what thread can use that piece of data. Once the thread is done with the piece of data it can unlock the data allowing other threads to have access to it.
\end{definition}
We need to remember two rules when we use mutex:\begin{enumerate}
    \item We need to aquire a lock before we have access to data.
    \item We have to release that lock when we are done with the data, so that other threads can have access.
\end{enumerate}

\paragraph*{Simple implementation}\begin{lstlisting}
    use std::sync::Mutex;

fn main() {
    let m = Mutex::new(5);

    {
        let mut num = m.lock().unwrap(); //Block current thread until that lock is aquired. Calling lock will fail if there is already another thread that has a lock to data and it panics, then our call will fail.  unwrap() makes us panic.
        *num = 6;
    }

    println!("m = {:?}", m); // value stored in m is 6
}
\end{lstlisting}
num is of type MutexGuard smart pointer. When MutexGuard goes out of scope it calls drop trait which will release lock to the data. 

\paragraph*{Sharing value between threads}\begin{lstlisting}
use std::sync::Mutex;
use std::thread;
use std::rc::Rc;

fn main() {
    let counter = Rc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10{
        let counter = Rc::clone(&counter); // At each iteration counter gets moved, so counter needs many owners
        let handle = thread::spawn(move ||{ // Error: Since Rc pointer is not thread safe
            let mut num = counter.lock().unwrap();

            *num +=1;
        });

        handles.push(handle);
    }

    for handle in handles{
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap());
}
\end{lstlisting}

So we want is something exactly like Rc but thread safe. We will use atomic reference counting smart pointer.
\paragraph*{Fixed with Arc}\begin{lstlisting}
use std::sync::{Arc,Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10{
        let counter = Arc::clone(&counter); // At each iteration counter gets moved, so counter needs many owners
        let handle = thread::spawn(move ||{ // Error: Since Rc pointer is not thread safe
            let mut num = counter.lock().unwrap();

            *num +=1;
        });

        handles.push(handle);
    }

    for handle in handles{
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap());
}
\end{lstlisting}
Note counter is immutable but we can get mutable reference to value inside since Mutex uses interior mutability.

\begin{remark}
    Mutex may cause deadlocks.
\end{remark}

\subsection{Building concurrency features}

While the rust language provide few concurrency features, it does provide the building blocks for us to build our own or use features built by someone else.

Two basic concurrency concepts provided by std lib are the send and sync traits.

\section{Object Oriented Programming features in Rust}
When it comes to OOP there are three characteristics that all OOP languages share:\begin{itemize}
    \item Objects
    \item Encapsulation
    \item Inheritance
\end{itemize}

Let us talk about each of these characteristics and if they are supported in rust. Objects are made out of data and methods that operate on that data. 
\subsection{Objects}
In Rust structs and enums hold data and we can define impl blocs to create methods for them. So even if they are not called objects they function in the same way.

\subsection{Encapsulation}
\begin{definition}
    \textbf{Encapsulation} means that implementation details of an object are hidden from the code using that object. Code outside of the object can only interact with object through the public API. 
\end{definition}

Previously we learned how to use the pub keyword to decide which modules, types, function and methodes are public since everything is private by default.

\begin{lstlisting}
    pub struct AveragedCollection{ //struct is public so outside code can use it
        list: Vec<i32>, // fields are private
        average: f64,
    }
    impl AveragedCollection{
    pub fn add(&mut self, value:i32){
        self.list.push(value);
        self.update_average();
    }

    pub fn remove(&mut self) -> Option<i32>{
        let result = self.list.pop();
        match result {
            Some(value) =>{
                self.update_average();
                Some(value)
            }
            None => None,
        }
    }

    pub fn average(&self) -> f64{
        self.average
    }

    fn update_average(&mut self){ //private method
        let total: i32 = self.list.iter().sum();
        self.average = total as f64 / self.list.len() as f64;
    }
}
\end{lstlisting}

We can change everything that is private (for example using hashmap instead of vec), and as long as the signatures of the public functions stay the same code using our struct doesn't have to care.
\subsubsection{Inheritance}
\begin{definition}
    \textbf{Inheritance} is the ability of an object to inherit from another object's definition gaining the data and behaviour of that other object without having to define the data and behaviour itself. 
\end{definition}

Rust doesn't have this ability, you can't define a struct that inherits fields and methods from another struct. Rust has other tools we can use depending on why we are reaching for inheritance.

There are two main reason to use inheritance\begin{itemize}
    \item Code sharing, we can implement behaviour on one type and all other types that inherit from it can reuse that behaviour. In rust we can do this by using default trait method implementations. There is a limit, traits can only define methods not fields, but there is a proposal for them to define fields.
    \item Polymorphims, allows us to substitute multiple objects at run time if they share certain characterstic, in classical inhertence that is a parent class. For example we can have base class Vehicles, and have subclasses inherit from that such as Truck, Car, etc.. And if we have a function that takes in a Vehicle at runtime we can pass in a Truck, Car, etc.. to that function.
    Rust takes in a different approach, in Rust we use generic to abstract away concrete types and we use trait bounds to restrict the characteristic of those types. Rust also provides trait objects which are similar to generics but they use dynamic dispatch while generics use static dispatch. We will see more about this in the next part.
\end{itemize}


\section{Trait objects}
Imagine we were building a GUI library, where the goal is to take in a list of visual elements (i.e. buttons, text boxes, etc..) and draw them on the screen. We want users to be able to create their own visual components that can be drawn on the screen. At compile time we don't know the breath of objects used at compile time, but we know they will have a method called Draw.

\

If we were using a language with classical inheritance we may create a base class called visualComponents with a Draw method, where each visual component will inherit, or override with their own implement. 

\

In Rust we define shared behaviour using \textbf{traits}.

\begin{definition}
    Traits are define by first specifying some Pointer (like ref, or smart pointer) and use the dyn keyword followed by the relevant trait.
    
    \begin{lstlisting}
        pub components: Vec<Box<dyn Draw>>,
    \end{lstlisting}

When we define our trait object, at compile time Rust will make sure everything in the vector implements the Draw trait,
\end{definition}

Why shouldn't we use generics rather than trait objects? When we use generics we are limited to one type! \begin{lstlisting}
    pub struct Screen<T: Draw>{
    pub components: Vec<T>,
}
\end{lstlisting}

Then we can only store one type in our vector, either all buttons or all text boxes. Using trait objects we can store buttons, textboxes, etc... in the same vector.


\newpage
\paragraph*{lib.rs}\begin{lstlisting}
    pub trait Draw{
    fn draw(&self);
}

pub struct  Screen{
    pub components: Vec<Box<dyn Draw>>,
}

impl Screen{
    pub fn run(&self) {
        for component in self.components.iter(){
            component.draw();
        }
    }
}



pub struct Button{
    pub width: u32,
    pub height: u32,
    pub label: String,
}

impl Draw for Button{
    fn draw(&self){
        //draw button
    }
} // Note even though we must implement the Draw trait and draw() method for button, we can implement other methods as well. Like an on-click method.
\end{lstlisting}

\paragraph*{main.rs}\begin{lstlisting}
use gui_lib::{Screen, Button, Draw};

// Defining our own screen component,
struct SelectBox{
    width: u32,
    height: u32,
    options: Vec<String>,
}

impl Draw for SelectBox{
    fn draw(&self){
        //draw select box
    }
}

fn main(){
    let screen = Screen{
        components: vec![
           // Box::new(String::from("test")), Error since String doesn't implement draw
            Box::new(SelectBox{
                width: 100,
                height: 100,
                options: vec![
                    String::from("yes"),
                    String::from("no"),
                    String::from("maybe"),
                ]
            }),
            Box::new(Button{
                width: 100,
                height: 100,
                label: String::from("ok")
            })
        ],
    };

    screen.run();
}
\end{lstlisting}

\subsection{Static vs Dynamic dispatch}
\begin{definition}
    \textbf{Monomorphism}, is a process when the compiler will generate non-generic implementation of function based on concrete types used in place of generic types.
    
    For example, we have a function add, which takes two generic parameters and adds them, if we use that function with floats and integers the compile will create a function for integer\_add and float\_add and find the call sites of the add method and replace it with the concrete implementation.
    
    This is called \textbf{Static dispatch}; the compiler knows the concrete functions we are calling at compile time. The opposite is \textbf{dynamic dispatch}, the compile figures out what concrete methods we are running at run time. 
\end{definition}

When using trait objects, Rust compiler uses dynamic dispatch since it doesn't know all the concrete objects used at compile time. There is a runtime performance cost in using this, but we get to write flexible code that accepts any object that implements a certain trait.


\subsection{Object Safety}

We can only make object safe traits into trait bounds. A trait is object safe if all methods implemented on that trait have these properties\begin{definition}
    \item Return type is not \&self
    \item There are no generic parameters
\end{definition}

If the trait doesn't have these properties, the compiler can't figure out the concrete type of that trait and doesn't know what method to call.


\section{Implementing the state object oriented pattern}

In the state pattern we have some value that has internal state, represented by state object. Each state object is responsible for it's own behaviour and when to change state. The object containing the state objects knows nothing about the different behaviours or state or when to transition.

To understand how the state pattern works, we will implement a blog-post workflow in Rust.

\newpage

\paragraph*{lib.rs}\begin{lstlisting}
    pub struct  Post{
    state: Option<Box<dyn State>>,
    content: String,
}

impl Post{
    pub fn new() ->Post{
        Post { 
            state: Some(Box::new(Draft{})),
            content: String::new(), 
        }
    }

    pub fn add_text(&mut self, text: &str){
        self.content.push_str(text);
    }

    pub fn content(&self) -> &str{
        self.state.as_ref().unwrap().content(self)
    }

    pub fn request_review(&mut self){ // Method is the same no matter what state we are in.
        if let Some(state) = self.state.take(){ // take() takes value out of option and leaves None instead. Since Rust doesn't allow unpopulated struct fields, we need to wrap our field inside an Option to move it.
            self.state = Some(state.request_review());
        }
    }
    pub fn approve(&mut self){ // Method is the same no matter what state we are in.
        if let Some(state) = self.state.take(){ // take() takes value out of option and leaves None instead. Since Rust doesn't allow unpopulated struct fields, we need to wrap our field inside an Option to move it.
            self.state = Some(state.approve());
        }
    }
}

trait State {
    fn request_review(self: Box<Self>) -> Box<dyn State>;
    fn approve(self: Box<Self>) -> Box<dyn State>;
    fn content<'a>(&self, post:&'a Post) -> &'a str{
        ""
    }
}

struct Draft {}

impl State for Draft {
    fn request_review(self: Box<Self>) -> Box<dyn State>{
        Box::new(PendingReview {})
    }

    fn approve(self: Box<Self>) -> Box<dyn State> {
        self
    }
}

struct PendingReview {}

impl State for PendingReview{
    fn request_review(self: Box<Self>) -> Box<dyn State>{
        self
    }

    fn approve(self: Box<Self>) -> Box<dyn State> {
        Box::new(Published {})
    }
}

struct Published {}

impl State for Published {
    fn request_review(self: Box<Self>) -> Box<dyn State>{
        self
    }

    fn approve(self: Box<Self>) -> Box<dyn State> {
        self
    }

    fn content<'a>(&self, post:&'a Post) -> &'a str{ // Need to specify lifetimes 
        &post.content
    }
}
\end{lstlisting}
\paragraph*{main.rs}\begin{lstlisting}
    use blog::Post;

fn main() {
    let mut post = Post::new();

    post.add_text("I ate a salade for lunch today");
    assert_eq!("", post.content());

    post.request_review();
    assert_eq!("", post.content());

    post.approve();
    assert_eq!("I ate a salade for lunch today", post.content());
}
\end{lstlisting}
\begin{exercise}
\begin{itemize}
    \item Add another method called reject which takes post under review and returns it back to draft state.
    \item Make it so that two apporvals are required before a post is published
    \item Make it so that can only add text to a post when it is in draft mode.
\end{itemize}
\end{exercise}

One of the downsides of State Pattern is that some states are coupled to eachother, if we wanted to add a state between PendingReview and Published, then we would need to update the PendingReview state so that it doesn't transition to Published state.

Another downside is duplication, we have very similar implematation for request\_review and approve methods. By implementating the state pattern exactly as in OOP we are not taking full advantage of Rust, let's try a different approach. We will encode different states as different types.

\paragraph*{lib.rs}\begin{lstlisting}
    pub struct Post{
    content: String,
}

pub struct DraftPost{
    content: String,
}

impl Post{
    pub fn new() -> DraftPost{
        DraftPost { content: String::new(), }
    }

    pub fn content(&self)->&str{
        &&self.content
    }
}

impl DraftPost {
    pub fn add_text(&mut self, text: &str){
        self.content.push_str(text);
    }

    pub fn request_review(self) -> PendingReviewPost{
        PendingReviewPost { content: self.content, }
    }
}

pub struct  PendingReviewPost{
    content: String,
}

impl PendingReviewPost{
    pub fn approve(self) -> Post{
        Post { content: self.content, }
    }
}
\end{lstlisting}

\paragraph*{main.rs}\begin{lstlisting}
    use blog::Post;

fn main() {
    let mut post = Post::new();

    post.add_text("I ate a salade for lunch today");

    let post = post.request_review();

    let post = post.approve();
    assert_eq!("I ate a salade for lunch today", post.content());
}
\end{lstlisting}

This new implementation doesn't follow the OOP state pattern, but invalid states are now impossible due to they type system and type checking.
\end{document}
